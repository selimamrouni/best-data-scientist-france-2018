{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T19:41:06.346702Z",
     "start_time": "2018-06-06T19:41:06.344304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2018 Selim Amrouni. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T03:11:59.554288Z",
     "start_time": "2018-06-05T03:11:59.551880Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:03.012839Z",
     "start_time": "2018-06-07T00:19:02.942024Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import log_loss, fbeta_score, make_scorer, confusion_matrix, roc_curve\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T03:12:44.187123Z",
     "start_time": "2018-06-05T03:12:44.183795Z"
    }
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Label Emmaüs](https://www.label-emmaus.co/fr/) offers for sale objects renovated or created by the movement Emmaüs. The aim is to estimate the range of time to sale each object.\n",
    "\n",
    "This is a multi-labels classification, with 3 labels:\n",
    "\n",
    "- 0 : between 0 et 10 days\n",
    "- 1 : between 10 et 60 days\n",
    "- 2 : more than 60 days\n",
    "<br>\n",
    "The evaluation metric is multilogloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:08.111180Z",
     "start_time": "2018-06-07T00:19:07.898515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension X_train: (8880, 30)\n",
      "Dimension X_test: (2960, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2168: expected 31 fields, saw 33\\nSkipping line 4822: expected 31 fields, saw 37\\nSkipping line 4859: expected 31 fields, saw 37\\nSkipping line 7342: expected 31 fields, saw 37\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_images</th>\n",
       "      <th>longueur_image</th>\n",
       "      <th>largeur_image</th>\n",
       "      <th>url_image</th>\n",
       "      <th>description_produit</th>\n",
       "      <th>taille</th>\n",
       "      <th>matiere</th>\n",
       "      <th>age</th>\n",
       "      <th>garantie</th>\n",
       "      <th>annee</th>\n",
       "      <th>couleur</th>\n",
       "      <th>largeur_produit</th>\n",
       "      <th>wifi</th>\n",
       "      <th>etat</th>\n",
       "      <th>longueur_produit</th>\n",
       "      <th>pointure</th>\n",
       "      <th>vintage</th>\n",
       "      <th>marque</th>\n",
       "      <th>auteur</th>\n",
       "      <th>editions</th>\n",
       "      <th>hauteur_produit</th>\n",
       "      <th>poids</th>\n",
       "      <th>prix</th>\n",
       "      <th>categorie</th>\n",
       "      <th>sous_categorie_1</th>\n",
       "      <th>sous_categorie_2</th>\n",
       "      <th>sous_categorie_3</th>\n",
       "      <th>sous_categorie_4</th>\n",
       "      <th>nom_produit</th>\n",
       "      <th>nom_magasin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>2552.0</td>\n",
       "      <td>https://d1kvfoyrif6wzg.cloudfront.net/assets/i...</td>\n",
       "      <td>Superbe petit top bustier avec explosion de co...</td>\n",
       "      <td>44</td>\n",
       "      <td>100 % polyester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multicolore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bon état</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>mode</td>\n",
       "      <td>tops, t-shirts, débardeurs femme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Top bustier multicolore</td>\n",
       "      <td>Emmaüs 88 Neufchateau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2486.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>https://d1kvfoyrif6wzg.cloudfront.net/assets/i...</td>\n",
       "      <td>Radio ITT Océnic Flirt, année 70\\nPour déco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plastique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jaune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en l'état</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>ITT Océanic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>mobilier - deco</td>\n",
       "      <td>bibelots et objets déco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radio ITT Océanic</td>\n",
       "      <td>Communauté Emmaüs Thouars (magasin Parthenay)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>https://d1kvfoyrif6wzg.cloudfront.net/assets/i...</td>\n",
       "      <td>Veste boléro à manches courtes NÛMPH. Gris chi...</td>\n",
       "      <td>40</td>\n",
       "      <td>Polyester, coton, laine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neuf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Nûmph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>label selection</td>\n",
       "      <td>mode</td>\n",
       "      <td>mode femme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Label Emmaüs Chambéry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_images  longueur_image  largeur_image  \\\n",
       "id                                             \n",
       "0           3          3458.0         2552.0   \n",
       "1           2          2486.0         2254.0   \n",
       "2           3          1536.0         1536.0   \n",
       "\n",
       "                                            url_image  \\\n",
       "id                                                      \n",
       "0   https://d1kvfoyrif6wzg.cloudfront.net/assets/i...   \n",
       "1   https://d1kvfoyrif6wzg.cloudfront.net/assets/i...   \n",
       "2   https://d1kvfoyrif6wzg.cloudfront.net/assets/i...   \n",
       "\n",
       "                                  description_produit taille  \\\n",
       "id                                                             \n",
       "0   Superbe petit top bustier avec explosion de co...     44   \n",
       "1         Radio ITT Océnic Flirt, année 70\\nPour déco    NaN   \n",
       "2   Veste boléro à manches courtes NÛMPH. Gris chi...     40   \n",
       "\n",
       "                    matiere  age garantie  annee      couleur  \\\n",
       "id                                                              \n",
       "0          100 % polyester   NaN      NaN    NaN  Multicolore   \n",
       "1                 Plastique  NaN      NaN    NaN        Jaune   \n",
       "2   Polyester, coton, laine  NaN      NaN    NaN         Gris   \n",
       "\n",
       "    largeur_produit wifi       etat  longueur_produit  pointure vintage  \\\n",
       "id                                                                        \n",
       "0               NaN  NaN   bon état               NaN       NaN   False   \n",
       "1               NaN  NaN  en l'état               NaN       NaN    True   \n",
       "2               NaN  NaN       neuf               NaN       NaN   False   \n",
       "\n",
       "         marque auteur editions  hauteur_produit   poids  prix  \\\n",
       "id                                                               \n",
       "0           NaN    NaN      NaN              NaN   200.0   4.5   \n",
       "1   ITT Océanic    NaN      NaN              NaN  1000.0  15.0   \n",
       "2         Nûmph    NaN      NaN              NaN   360.0  16.0   \n",
       "\n",
       "          categorie                  sous_categorie_1 sous_categorie_2  \\\n",
       "id                                                                       \n",
       "0              mode  tops, t-shirts, débardeurs femme              NaN   \n",
       "1   mobilier - deco           bibelots et objets déco              NaN   \n",
       "2   label selection                              mode       mode femme   \n",
       "\n",
       "   sous_categorie_3 sous_categorie_4               nom_produit  \\\n",
       "id                                                               \n",
       "0               NaN              NaN  Top bustier multicolore    \n",
       "1               NaN              NaN         Radio ITT Océanic   \n",
       "2               NaN              NaN                       NaN   \n",
       "\n",
       "                                      nom_magasin  \n",
       "id                                                 \n",
       "0                           Emmaüs 88 Neufchateau  \n",
       "1   Communauté Emmaüs Thouars (magasin Parthenay)  \n",
       "2                           Label Emmaüs Chambéry  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\", index_col=0, error_bad_lines=False)\n",
    "X_test = pd.read_csv(\"X_test.csv\", index_col=0, error_bad_lines=False)\n",
    "y_train = pd.read_csv(\"y_train.csv\", index_col=0)\n",
    "\n",
    "print(\"Dimension X_train:\", X_train.shape)\n",
    "print(\"Dimension X_test:\", X_test.shape)\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T05:07:51.738395Z",
     "start_time": "2018-06-05T05:07:51.735783Z"
    }
   },
   "source": [
    "The training dataset is the one we have to train the model, we know the labels with y_train. <br>\n",
    "For the test dataset, we don't know y_test. This is the one we have to submit the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, let's split the X_train in 2 parts. <br> We split it randomly in order to get a validation dataset. It will enable us to know the performances of the model before the submission with totally unseen data. <br>\n",
    "Note that for the final submission, we'll train the chosen model with the whole training dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T15:09:28.689936Z",
     "start_time": "2018-06-05T15:09:28.671628Z"
    }
   },
   "source": [
    "## Split X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:08.133180Z",
     "start_time": "2018-06-07T00:19:08.114730Z"
    }
   },
   "outputs": [],
   "source": [
    "# we save y_train for later with X_train\n",
    "Y_train = y_train\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T03:17:52.605156Z",
     "start_time": "2018-06-05T03:17:52.602257Z"
    }
   },
   "source": [
    "## NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 30 different features. However, it seems many have a lot of NaN values. Let's see which ones have enough data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the percentage of missing values per columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:10.289633Z",
     "start_time": "2018-06-07T00:19:10.272689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nb_images               0.0\n",
       "longueur_image          1.0\n",
       "largeur_image           1.0\n",
       "url_image               1.0\n",
       "description_produit     0.0\n",
       "taille                 72.0\n",
       "matiere                55.0\n",
       "age                    99.0\n",
       "garantie               99.0\n",
       "annee                  83.0\n",
       "couleur                40.0\n",
       "largeur_produit        99.0\n",
       "wifi                   99.0\n",
       "etat                    0.0\n",
       "longueur_produit       99.0\n",
       "pointure               97.0\n",
       "vintage                33.0\n",
       "marque                 51.0\n",
       "auteur                 84.0\n",
       "editions               84.0\n",
       "hauteur_produit        99.0\n",
       "poids                   0.0\n",
       "prix                    0.0\n",
       "categorie               0.0\n",
       "sous_categorie_1       18.0\n",
       "sous_categorie_2       59.0\n",
       "sous_categorie_3       90.0\n",
       "sous_categorie_4       99.0\n",
       "nom_produit             9.0\n",
       "nom_magasin             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*x_train.isnull().sum()/len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of columns are missing a lot of values:\n",
    "- taille\n",
    "- matiere\n",
    "- age\n",
    "- garantie\n",
    "- annee\n",
    "- couleur\n",
    "- largeur_produit\n",
    "- wifi\n",
    "- longueur_produit\n",
    "- pointure\n",
    "- marque\n",
    "- auteur\n",
    "- editions\n",
    "- hauteur_produit\n",
    "- sous_categorie_2\n",
    "- sous_categorie_3\n",
    "- sous_categorie_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:10.312471Z",
     "start_time": "2018-06-07T00:19:10.292754Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['taille', 'matiere', 'age', 'garantie', 'annee', 'couleur', 'largeur_produit', 'wifi',\n",
    "                        'longueur_produit', 'pointure', 'marque', 'auteur', 'editions', 'hauteur_produit',\n",
    "                        'sous_categorie_2', 'sous_categorie_3', 'sous_categorie_4'], axis=1)\n",
    "\n",
    "x_train = x_train.drop(['taille', 'matiere', 'age', 'garantie', 'annee', 'couleur', 'largeur_produit', 'wifi',\n",
    "                        'longueur_produit', 'pointure', 'marque', 'auteur', 'editions', 'hauteur_produit',\n",
    "                        'sous_categorie_2', 'sous_categorie_3', 'sous_categorie_4'], axis=1)\n",
    "\n",
    "x_val = x_val.drop(['taille', 'matiere', 'age', 'garantie', 'annee', 'couleur', 'largeur_produit', 'wifi',\n",
    "                    'longueur_produit', 'pointure', 'marque', 'auteur', 'editions', 'hauteur_produit',\n",
    "                    'sous_categorie_2', 'sous_categorie_3', 'sous_categorie_4'], axis=1)\n",
    "\n",
    "X_test = X_test.drop(['taille', 'matiere', 'age', 'garantie', 'annee', 'couleur', 'largeur_produit', 'wifi',\n",
    "                      'longueur_produit', 'pointure', 'marque', 'auteur', 'editions', 'hauteur_produit',\n",
    "                      'sous_categorie_2', 'sous_categorie_3', 'sous_categorie_4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:11.044003Z",
     "start_time": "2018-06-07T00:19:11.021876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_images</th>\n",
       "      <th>longueur_image</th>\n",
       "      <th>largeur_image</th>\n",
       "      <th>url_image</th>\n",
       "      <th>description_produit</th>\n",
       "      <th>etat</th>\n",
       "      <th>vintage</th>\n",
       "      <th>poids</th>\n",
       "      <th>prix</th>\n",
       "      <th>categorie</th>\n",
       "      <th>sous_categorie_1</th>\n",
       "      <th>nom_produit</th>\n",
       "      <th>nom_magasin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>3</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>https://d1kvfoyrif6wzg.cloudfront.net/assets/i...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Robe Bustier Femme ZARA&lt;/strong&gt;&lt;/p...</td>\n",
       "      <td>neuf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>mode</td>\n",
       "      <td>robes</td>\n",
       "      <td>ZARA - T40 ( ref.d39 )</td>\n",
       "      <td>Tri d'Union - la boutique en ligne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528</th>\n",
       "      <td>5</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>2287.0</td>\n",
       "      <td>https://d1kvfoyrif6wzg.cloudfront.net/assets/i...</td>\n",
       "      <td>Couturière en herbe , ranger une partie de vot...</td>\n",
       "      <td>bon état</td>\n",
       "      <td>True</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>loisirs</td>\n",
       "      <td>mobilier - deco</td>\n",
       "      <td>Travailleuse couture vintage</td>\n",
       "      <td>Emmaüs 88 Neufchateau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>5</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>https://d1kvfoyrif6wzg.cloudfront.net/assets/i...</td>\n",
       "      <td>Pot en terre made in Mexico.\\nPoterie brute no...</td>\n",
       "      <td>bon état</td>\n",
       "      <td>False</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>mobilier - deco</td>\n",
       "      <td>Vases et Pots</td>\n",
       "      <td>Pot cache pot poterie made in Mexico</td>\n",
       "      <td>Frip'Insertion Marseille Libération</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_images  longueur_image  largeur_image  \\\n",
       "id                                               \n",
       "5540          3          1600.0          900.0   \n",
       "5528          5          2450.0         2287.0   \n",
       "3434          5          2200.0         2200.0   \n",
       "\n",
       "                                              url_image  \\\n",
       "id                                                        \n",
       "5540  https://d1kvfoyrif6wzg.cloudfront.net/assets/i...   \n",
       "5528  https://d1kvfoyrif6wzg.cloudfront.net/assets/i...   \n",
       "3434  https://d1kvfoyrif6wzg.cloudfront.net/assets/i...   \n",
       "\n",
       "                                    description_produit      etat vintage  \\\n",
       "id                                                                          \n",
       "5540  <p><strong>Robe Bustier Femme ZARA</strong></p...      neuf     NaN   \n",
       "5528  Couturière en herbe , ranger une partie de vot...  bon état    True   \n",
       "3434  Pot en terre made in Mexico.\\nPoterie brute no...  bon état   False   \n",
       "\n",
       "       poids  prix        categorie sous_categorie_1  \\\n",
       "id                                                     \n",
       "5540   500.0   7.0             mode            robes   \n",
       "5528  3400.0  30.0          loisirs  mobilier - deco   \n",
       "3434  1300.0   6.0  mobilier - deco    Vases et Pots   \n",
       "\n",
       "                               nom_produit  \\\n",
       "id                                           \n",
       "5540                ZARA - T40 ( ref.d39 )   \n",
       "5528         Travailleuse couture vintage    \n",
       "3434  Pot cache pot poterie made in Mexico   \n",
       "\n",
       "                              nom_magasin  \n",
       "id                                         \n",
       "5540   Tri d'Union - la boutique en ligne  \n",
       "5528                Emmaüs 88 Neufchateau  \n",
       "3434  Frip'Insertion Marseille Libération  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T03:50:13.221753Z",
     "start_time": "2018-06-05T03:50:13.168253Z"
    }
   },
   "source": [
    "That's a lot of removed features. Now, we can focus on the remaining data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are data are different types:\n",
    "- Categorical: \n",
    " - etat\n",
    " - vintage\n",
    " - categorie\n",
    " - sous_categorie_1\n",
    " - nom_magasin\n",
    "- Text:\n",
    " - url_image\n",
    " - description_produit\n",
    " - nom_produit\n",
    "- Numerical:\n",
    " - nb_images\n",
    " - longueur_image\n",
    " - largeur_image\n",
    " - poids\n",
    " - prix\n",
    " \n",
    " \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T04:05:08.105850Z",
     "start_time": "2018-06-05T04:05:08.102910Z"
    }
   },
   "source": [
    "### Numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep these data and do not apply any transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T04:06:26.131530Z",
     "start_time": "2018-06-05T04:06:26.128864Z"
    }
   },
   "source": [
    "#### etat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:12.385429Z",
     "start_time": "2018-06-07T00:19:12.378471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bon état         3162\n",
       "en l'état        1108\n",
       "comme neuf        767\n",
       "reconditionné     644\n",
       "neuf              516\n",
       "Name: etat, dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.etat.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few categories and there is a relation of order between these data. <br>\n",
    "neuf > comme neuf > reconditionné > bon état > en l'état <br>\n",
    "<br>\n",
    "Let's replace these categorie by corresponding integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:13.111327Z",
     "start_time": "2018-06-07T00:19:13.095029Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace(data):\n",
    "    if data == 'en l\\'état':\n",
    "        return 0\n",
    "    elif data == 'bon état':\n",
    "        return 1\n",
    "    elif data == 'reconditionné':\n",
    "        return 2\n",
    "    elif data == 'comme neuf':\n",
    "        return 3\n",
    "    elif data == 'neuf':\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:13.493219Z",
     "start_time": "2018-06-07T00:19:13.113530Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.etat = x_train.apply(lambda x: replace(x.etat), axis=1)\n",
    "x_val.etat = x_val.apply(lambda x: replace(x.etat), axis=1)\n",
    "X_test.etat = X_test.apply(lambda x: replace(x.etat), axis=1)\n",
    "X_train.etat = X_train.apply(lambda x: replace(x.etat), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vintage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:14.954542Z",
     "start_time": "2018-06-07T00:19:14.946801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2728\n",
       "True     1439\n",
       "Name: vintage, dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.vintage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:15.347985Z",
     "start_time": "2018-06-07T00:19:14.957401Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace(data):\n",
    "    if data == True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "X_train.vintage = X_train.apply(lambda x: replace(x.vintage), axis=1)\n",
    "\n",
    "x_train.vintage = x_train.apply(lambda x: replace(x.vintage), axis=1)\n",
    "x_val.vintage = x_val.apply(lambda x: replace(x.vintage), axis=1)\n",
    "\n",
    "X_test.vintage = X_test.apply(lambda x: replace(x.vintage), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:16.099303Z",
     "start_time": "2018-06-07T00:19:16.091823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode                               2117\n",
       "mobilier - deco                    1265\n",
       "librairie                          1024\n",
       "label selection                     656\n",
       "loisirs                             576\n",
       "enfance                             380\n",
       "multimédia                           95\n",
       "les coups de coeur des vendeurs      34\n",
       "culture - loisirs                    31\n",
       "mobilier - deco - maison             28\n",
       "créations                             9\n",
       "Name: categorie, dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.categorie.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a several un-ordered data. However, we can group some data because of the same type:\n",
    "- mobilier - deco & mobilier - deco - maison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:17.340940Z",
     "start_time": "2018-06-07T00:19:16.817916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode                               2117\n",
       "mobilier - deco                    1293\n",
       "librairie                          1024\n",
       "label selection                     656\n",
       "loisirs                             576\n",
       "enfance                             380\n",
       "multimédia                           95\n",
       "les coups de coeur des vendeurs      34\n",
       "culture - loisirs                    31\n",
       "créations                             9\n",
       "Name: categorie, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace(data):\n",
    "    if data == 'mobilier - deco - maison':\n",
    "        return 'mobilier - deco'\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "X_train.categorie = X_train.apply(lambda x: replace(x.categorie), axis=1)\n",
    "\n",
    "x_train.categorie = x_train.apply(lambda x: replace(x.categorie), axis=1)\n",
    "x_val.categorie = x_val.apply(lambda x: replace(x.categorie), axis=1)\n",
    "X_test.categorie = X_test.apply(lambda x: replace(x.categorie), axis=1)\n",
    "\n",
    "x_train.categorie.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no ordering relation between these categories. So we can't replace by integers. <br>\n",
    "We can use the one-hot encoding method to replace these variables. So, each category is replace by a binary variable. <br>\n",
    "This method is implemented in keras or scikit-learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T04:35:19.847040Z",
     "start_time": "2018-06-05T04:35:19.844265Z"
    }
   },
   "source": [
    "### sous_categorie_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:18.831991Z",
     "start_time": "2018-06-07T00:19:18.823465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode                                                 372\n",
       "bibelots et objets déco                              335\n",
       "label selection                                      263\n",
       "robes                                                213\n",
       "accessoires femme                                    210\n",
       "sacs, maroquinerie                                   160\n",
       "objets d'art, antiquités                             146\n",
       "autres objets                                        139\n",
       "vestes, blazers femme                                131\n",
       "tops, t-shirts, débardeurs femme                     123\n",
       "mobilier - deco                                      121\n",
       "jupes, shorts femme                                  121\n",
       "tableaux, miroirs, déco murale                       110\n",
       "chemisiers, blouses, tuniques femme                  104\n",
       "vinyles                                              100\n",
       "chaussures et bottes femme                            97\n",
       "vaisselle à l'unité                                   93\n",
       "appareils photo et accessoires photo                  92\n",
       "gilets, pulls femme                                   92\n",
       "services de vaisselle, vaisselle en lots              89\n",
       "pantalons femme                                       86\n",
       "jouets anciens, jouets en bois                        76\n",
       "manteaux, blousons femme                              73\n",
       "accessoires homme                                     69\n",
       "luminaires                                            66\n",
       "enfance                                               61\n",
       "gilets, pulls homme                                   56\n",
       "jeux de société, puzzles                              56\n",
       "Vases et Pots                                         49\n",
       "loisirs                                               47\n",
       "                                                    ... \n",
       "tablettes                                              1\n",
       "Déco Kitsch                                            1\n",
       "On continue, l'abbé !                                  1\n",
       "imprimantes                                            1\n",
       "Métiers d'hier                                         1\n",
       "gros mobilier                                          1\n",
       "petit mobilier                                         1\n",
       "Journée de la femme                                    1\n",
       "buffets, enfilades                                     1\n",
       "Le Ski                                                 1\n",
       "fournitures et papeterie                               1\n",
       "Déco Couleurs Naturelles et Doré                       1\n",
       "Shabby Chic                                            1\n",
       "meubles de métier                                      1\n",
       "loisirs créatifs, couture, mercerie, déguisements      1\n",
       "vêtements de sport enfant                              1\n",
       "Noël                                                   1\n",
       "Enfin le printemps !                                   1\n",
       "Horloges, Pendules, Réveils                            1\n",
       "mobiles                                                1\n",
       "poussettes, couffins                                   1\n",
       "armoires, vitrines, bibliothèques                      1\n",
       "bricolage                                              1\n",
       "A carreaux !                                           1\n",
       "Fête de la musique                                     1\n",
       "Denim pour tous !                                      1\n",
       "Cérémonies                                             1\n",
       "canapés, banquettes, bancs                             1\n",
       "Pub et Réclame                                         1\n",
       "Vélorution !                                           1\n",
       "Name: sous_categorie_1, Length: 162, dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.sous_categorie_1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 169 different categories. This is a lot. The problem comes up because it will generate a lot of binary variables if we directly use one-hote encoding. <br>\n",
    "This category is heavy, let's see later the exploitation of this one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nom_magasin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:19.652352Z",
     "start_time": "2018-06-07T00:19:19.642574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emmaüs Lyon                                               10.28\n",
       "Emmaüs 88 Neufchateau                                      9.03\n",
       "Label Emmaüs Chambéry                                      7.66\n",
       "ADBook - la Librairie Solidaire des Ateliers du Bocage     7.45\n",
       "Tri d'Union - la boutique en ligne                         6.61\n",
       "Le Léopard                                                 5.37\n",
       "Emmaüs Sacré Dressing !                                    5.07\n",
       "Label Emmaüs de Grenoble                                   4.05\n",
       "Label Emmaus Angers                                        3.14\n",
       "Frip'Insertion Marseille Libération                        3.12\n",
       "Booki - la Librairie Solidaire de Retrilog                 3.06\n",
       "Emmaüs Saintes Saint Romain                                2.61\n",
       "Emmaüs Avenir Neuilly sur Marne                            2.48\n",
       "Emmaüs Alternatives Sélection                              2.25\n",
       "La Boutique Emmaüs de Lorient Plénéno                      2.20\n",
       "La Boutique Emmaüs d’Auray                                 2.16\n",
       "La Boutique Emmaüs Pontivy                                 2.09\n",
       "Frip'Attitude Emmaüs Vêtement                              2.04\n",
       "Ding Fring – En mode solidaire                             1.90\n",
       "Emmaüs Indre Le Blanc                                      1.85\n",
       "Emmaüs Liberté Ivry                                        1.83\n",
       "Emmaüs Vannes - la Boutique en ligne                       1.69\n",
       "Emmaüs St Etienne - Firminy                                1.53\n",
       "Comité d'amis Emmaüs Millau                                1.50\n",
       "Communauté Emmaüs Soissons                                 1.45\n",
       "La Bootique des Ateliers du Bocage                         1.08\n",
       "Emmaüs Défi 104                                            1.01\n",
       "Ding Fring - En page solidaire                             0.87\n",
       "Emmaus Chenôve                                             0.84\n",
       "Comité d'amis Emmaüs Beauvais                              0.58\n",
       "Comité d'amis Emmaüs Roanne Mably                          0.47\n",
       "Communauté Emmaüs Thouars (magasin Parthenay)              0.40\n",
       "Comité d'amis Emmaüs Pont Audemer                          0.39\n",
       "Tri Rhône-Alpes - la Boutique en ligne                     0.37\n",
       "Communauté Emmaüs Angoulême                                0.31\n",
       "Labelemmaus Vendée                                         0.27\n",
       "L'Abri 88                                                  0.19\n",
       "Le coin de l'e-chineur                                     0.19\n",
       "Emmaüs Mobilier Pro                                        0.18\n",
       "Comité d'amis Emmaüs Ruffec                                0.18\n",
       "Librairie Colibrio                                         0.13\n",
       "Atelier Emmaüs                                             0.08\n",
       "La Boutique militante : Article 13                         0.03\n",
       "Communauté Emmaüs Thouars                                  0.02\n",
       "Boutique des amis d'Emmaüs Apt                             0.02\n",
       "Name: nom_magasin, dtype: float64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(x_train.nom_magasin.value_counts()/len(x_train)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:19.663959Z",
     "start_time": "2018-06-07T00:19:19.654991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train.nom_magasin.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:20.378699Z",
     "start_time": "2018-06-07T00:19:20.361816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nom_magasin\n",
       "ADBook - la Librairie Solidaire des Ateliers du Bocage    1.256296\n",
       "Atelier Emmaüs                                            0.571429\n",
       "Booki - la Librairie Solidaire de Retrilog                1.287770\n",
       "Boutique des amis d'Emmaüs Apt                            0.000000\n",
       "Comité d'amis Emmaüs Beauvais                             0.725490\n",
       "Comité d'amis Emmaüs Millau                               0.931298\n",
       "Comité d'amis Emmaüs Pont Audemer                         0.702703\n",
       "Comité d'amis Emmaüs Roanne Mably                         0.666667\n",
       "Comité d'amis Emmaüs Ruffec                               0.142857\n",
       "Comité d'amis Emmaüs le Puy en Velay                      0.000000\n",
       "Communauté Emmaüs Angoulême                               0.413793\n",
       "Communauté Emmaüs Soissons                                0.310924\n",
       "Communauté Emmaüs Thouars                                 0.000000\n",
       "Communauté Emmaüs Thouars (magasin Parthenay)             0.416667\n",
       "Ding Fring - En page solidaire                            1.246914\n",
       "Ding Fring – En mode solidaire                            1.122093\n",
       "Emmaus Chenôve                                            1.420455\n",
       "Emmaüs 88 Neufchateau                                     0.958076\n",
       "Emmaüs Alternatives Sélection                             0.862559\n",
       "Emmaüs Avenir Neuilly sur Marne                           1.264574\n",
       "Emmaüs Défi 104                                           0.831461\n",
       "Emmaüs Indre Le Blanc                                     1.000000\n",
       "Emmaüs Liberté Ivry                                       1.000000\n",
       "Emmaüs Lyon                                               1.073743\n",
       "Emmaüs Mobilier Pro                                       1.500000\n",
       "Emmaüs Sacré Dressing !                                   0.647186\n",
       "Emmaüs Saintes Saint Romain                               0.566524\n",
       "Emmaüs St Etienne - Firminy                               1.167883\n",
       "Emmaüs Vannes - la Boutique en ligne                      1.078947\n",
       "Frip'Attitude Emmaüs Vêtement                             1.090361\n",
       "Frip'Insertion Marseille Libération                       0.760148\n",
       "L'Abri 88                                                 0.055556\n",
       "La Bootique des Ateliers du Bocage                        0.740385\n",
       "La Boutique Emmaüs Pontivy                                0.585227\n",
       "La Boutique Emmaüs de Lorient Plénéno                     0.636364\n",
       "La Boutique Emmaüs d’Auray                                0.556701\n",
       "La Boutique militante : Article 13                        0.500000\n",
       "Label Emmaus Angers                                       1.240418\n",
       "Label Emmaüs Chambéry                                     0.969743\n",
       "Label Emmaüs de Grenoble                                  1.002618\n",
       "Labelemmaus Vendée                                        0.260870\n",
       "Le Léopard                                                1.155756\n",
       "Le coin de l'e-chineur                                    0.812500\n",
       "Librairie Colibrio                                        0.000000\n",
       "Tri Rhône-Alpes - la Boutique en ligne                    1.333333\n",
       "Tri d'Union - la boutique en ligne                        1.309883\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = X_train.copy()\n",
    "df['label'] = Y_train\n",
    "df.groupby('nom_magasin').mean()['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of categories (46). We can want to reduce the number by grouping stores together: let's say we keep top15 in volume of sells and then group the rest under one label. <br><br>\n",
    "However, as shown above, the feature 'nom_magasin' seems really important because this is a feature with a great variance. <br>So we keep all the labels.\n",
    "\n",
    "\n",
    "There is no ordering relation, so we'll use one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:21.221839Z",
     "start_time": "2018-06-07T00:19:21.215873Z"
    }
   },
   "outputs": [],
   "source": [
    "# list_top_15 = list(X_train.nom_magasin.value_counts().index[0:15])\n",
    "# def replace(data):\n",
    "#     if data in list_top_15:\n",
    "#         return data\n",
    "#     else:\n",
    "#         return 'other_store'\n",
    "\n",
    "    \n",
    "# X_train.nom_magasin = X_train.apply(lambda x: replace(x.nom_magasin), axis = 1)\n",
    "# x_train.nom_magasin = x_train.apply(lambda x: replace(x.nom_magasin), axis = 1)\n",
    "# x_val.nom_magasin = x_val.apply(lambda x: replace(x.nom_magasin), axis = 1)\n",
    "# X_test.nom_magasin = X_test.apply(lambda x: replace(x.nom_magasin), axis = 1)\n",
    "\n",
    "# round(X_train.nom_magasin.value_counts()/len(X_train)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### url_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature seems not relevant. Let's remove it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### description_produit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T05:00:39.399549Z",
     "start_time": "2018-06-05T05:00:39.371132Z"
    }
   },
   "source": [
    "This feature is pure text. It is a description of the product. I assume this feature should be useful. Indeed, this translate the sentiment of the author when he sees the product. So this should be the sentiment of a potential buyer. <br>\n",
    "Further exploration should be done with text mining technics.<br> <br>\n",
    "Also, we can assume the length of the description and the title(nom_produit) are 2 important features. Indeed, a long description could attract a potential buyer: more details. We also count the number of words because it demonstrates the richness of the vocabulary: a rich vocabulary could be used for really nice products/a poorest for less attractive product. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nom_produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:22.340214Z",
     "start_time": "2018-06-07T00:19:22.334576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "5540                               ZARA - T40 ( ref.d39 )\n",
       "5528                        Travailleuse couture vintage \n",
       "3434                 Pot cache pot poterie made in Mexico\n",
       "5621    Souveraineté du vide. Lettres d'or - Christian...\n",
       "5267                             Ancienne Poupée Corolle \n",
       "2589                                                  NaN\n",
       "4782                                                  NaN\n",
       "Name: nom_produit, dtype: object"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.nom_produit.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same remark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T05:05:46.582561Z",
     "start_time": "2018-06-05T05:05:46.579927Z"
    }
   },
   "source": [
    "### Text Mining "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T22:31:46.460981Z",
     "start_time": "2018-06-06T22:31:46.442494Z"
    }
   },
   "source": [
    "First we need to clean the NaN sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:23.005678Z",
     "start_time": "2018-06-07T00:19:22.990116Z"
    }
   },
   "outputs": [],
   "source": [
    "x_val.nom_magasin.fillna('', inplace=True)\n",
    "X_test.nom_magasin.fillna('', inplace=True)\n",
    "X_train.nom_magasin.fillna('', inplace=True)\n",
    "x_train.nom_magasin.fillna('', inplace=True)\n",
    "\n",
    "x_val.nom_produit.fillna('', inplace=True)\n",
    "X_test.nom_produit.fillna('', inplace=True)\n",
    "X_train.nom_produit.fillna('', inplace=True)\n",
    "x_train.nom_produit.fillna('', inplace=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T20:23:34.719384Z",
     "start_time": "2018-06-06T20:23:34.714367Z"
    }
   },
   "source": [
    "#### Length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:23.654926Z",
     "start_time": "2018-06-07T00:19:23.648755Z"
    }
   },
   "outputs": [],
   "source": [
    "def length_character(var):\n",
    "    \"\"\"Takes a string returns the number of characters \"\"\"\n",
    "    return len(var)\n",
    "\n",
    "\n",
    "def length_word(var):\n",
    "    \"\"\"Takes a string and returns the numbers of words\"\"\"\n",
    "    return len(var.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:25.668407Z",
     "start_time": "2018-06-07T00:19:23.657319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start description_car\n",
      "ok1\n",
      "ok2\n",
      "ok3\n",
      "ok4\n",
      "start description_wor\n",
      "ok1\n",
      "ok2\n",
      "ok3\n",
      "ok4\n",
      "start sentiment\n",
      "ok1\n",
      "ok2\n",
      "ok3\n",
      "ok4\n",
      "start subjectivity\n",
      "ok1\n",
      "ok2\n",
      "ok3\n",
      "ok4\n"
     ]
    }
   ],
   "source": [
    "list_column_to_add = ['description_car',\n",
    "                      'description_wor', 'nom_car', 'nom_wor']\n",
    "\n",
    "for c in list_column_to_add:\n",
    "    X_train[c] = 0\n",
    "    x_train[c] = 0\n",
    "    x_val[c] = 0\n",
    "    X_test[c] = 0\n",
    "\n",
    "\n",
    "print('start description_car')\n",
    "\n",
    "X_train.description_car = X_train.apply(\n",
    "    lambda x: length_character(x.description_produit), axis=1)\n",
    "print('ok1')\n",
    "x_train.description_car = x_train.apply(\n",
    "    lambda x: length_character(x.description_produit), axis=1)\n",
    "print('ok2')\n",
    "x_val.description_car = x_val.apply(\n",
    "    lambda x: length_character(x.description_produit), axis=1)\n",
    "print('ok3')\n",
    "X_test.description_car = X_test.apply(\n",
    "    lambda x: length_character(x.description_produit), axis=1)\n",
    "print('ok4')\n",
    "\n",
    "print('start description_wor')\n",
    "X_train.description_wor = X_train.apply(\n",
    "    lambda x: length_word(x.description_produit), axis=1)\n",
    "print('ok1')\n",
    "x_train.description_wor = x_train.apply(\n",
    "    lambda x: length_word(x.description_produit), axis=1)\n",
    "print('ok2')\n",
    "x_val.description_wor = x_val.apply(\n",
    "    lambda x: length_word(x.description_produit), axis=1)\n",
    "print('ok3')\n",
    "X_test.description_wor = X_test.apply(\n",
    "    lambda x: length_word(x.description_produit), axis=1)\n",
    "print('ok4')\n",
    "\n",
    "print('start sentiment')\n",
    "\n",
    "X_train.nom_car = X_train.apply(\n",
    "    lambda x: length_character(x.nom_produit), axis=1)\n",
    "print('ok1')\n",
    "x_train.nom_car = x_train.apply(\n",
    "    lambda x: length_character(x.nom_produit), axis=1)\n",
    "print('ok2')\n",
    "x_val.nom_car = x_val.apply(lambda x: length_character(x.nom_produit), axis=1)\n",
    "print('ok3')\n",
    "X_test.nom_car = X_test.apply(\n",
    "    lambda x: length_character(x.nom_produit), axis=1)\n",
    "print('ok4')\n",
    "\n",
    "print('start subjectivity')\n",
    "X_train.nom_wor = X_train.apply(lambda x: length_word(x.nom_produit), axis=1)\n",
    "print('ok1')\n",
    "x_train.nom_wor = x_train.apply(lambda x: length_word(x.nom_produit), axis=1)\n",
    "print('ok2')\n",
    "x_val.nom_wor = x_val.apply(lambda x: length_word(x.nom_produit), axis=1)\n",
    "print('ok3')\n",
    "X_test.nom_wor = X_test.apply(lambda x: length_word(x.nom_produit), axis=1)\n",
    "print('ok4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: All the texts are in French. So it requires us to use French text sentiment analysis tools. I am not used with sentiment analysis in French but there is one declination of textblob which enables us to do so. Let's use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:27.162187Z",
     "start_time": "2018-06-07T00:19:27.157949Z"
    }
   },
   "outputs": [],
   "source": [
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:28.004181Z",
     "start_time": "2018-06-07T00:19:27.996264Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sentiment_score(text):\n",
    "    \"\"\"\n",
    "    The API returns a tuple (score, subjectivity)\n",
    "    \"\"\"\n",
    "    return tb(text).sentiment[0]\n",
    "\n",
    "\n",
    "def get_subjectivity_score(text):\n",
    "    \"\"\"\n",
    "    The API returns a tuple (score, subjectivity)\n",
    "    \"\"\"\n",
    "    return tb(text).sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:53.751049Z",
     "start_time": "2018-06-07T00:19:28.006914Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sentiment\n",
      "ok1\n",
      "ok2\n",
      "ok3\n",
      "ok4\n",
      "start subjectivity\n",
      "ok1\n",
      "ok2\n",
      "ok3\n",
      "ok4\n"
     ]
    }
   ],
   "source": [
    "# create columns\n",
    "\n",
    "list_column_to_add = ['description_sentiment', 'description_subjectivity']\n",
    "\n",
    "for c in list_column_to_add:\n",
    "    X_train[c] = 0\n",
    "    x_train[c] = 0\n",
    "    x_val[c] = 0\n",
    "    X_test[c] = 0\n",
    "\n",
    "\n",
    "print('start sentiment')\n",
    "\n",
    "X_train.description_sentiment = X_train.apply(\n",
    "    lambda x: get_sentiment_score(x.description_produit), axis=1)\n",
    "print('ok1')\n",
    "x_train.description_sentiment = x_train.apply(\n",
    "    lambda x: get_sentiment_score(x.description_produit), axis=1)\n",
    "print('ok2')\n",
    "x_val.description_sentiment = x_val.apply(\n",
    "    lambda x: get_sentiment_score(x.description_produit), axis=1)\n",
    "print('ok3')\n",
    "X_test.description_sentiment = X_test.apply(\n",
    "    lambda x: get_sentiment_score(x.description_produit), axis=1)\n",
    "print('ok4')\n",
    "\n",
    "print('start subjectivity')\n",
    "X_train.description_subjectivity = X_train.apply(\n",
    "    lambda x: get_subjectivity_score(x.description_produit), axis=1)\n",
    "print('ok1')\n",
    "x_train.description_subjectivity = x_train.apply(\n",
    "    lambda x: get_subjectivity_score(x.description_produit), axis=1)\n",
    "print('ok2')\n",
    "x_val.description_subjectivity = x_val.apply(\n",
    "    lambda x: get_subjectivity_score(x.description_produit), axis=1)\n",
    "print('ok3')\n",
    "X_test.description_subjectivity = X_test.apply(\n",
    "    lambda x: get_subjectivity_score(x.description_produit), axis=1)\n",
    "print('ok4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll not use the description_produit anymore so let's delete them. <br>\n",
    "Also, I'll not use the nom_produit anymore so let's delete them. <br>\n",
    "Same for url_image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:55.355644Z",
     "start_time": "2018-06-07T00:19:55.340523Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train.drop(\n",
    "    ['url_image', 'nom_produit', 'description_produit'], axis=1)\n",
    "x_val = x_val.drop(['url_image', 'nom_produit', 'description_produit'], axis=1)\n",
    "X_train = X_train.drop(\n",
    "    ['url_image', 'nom_produit', 'description_produit'], axis=1)\n",
    "X_test = X_test.drop(\n",
    "    ['url_image', 'nom_produit', 'description_produit'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we still have some missing values, let's fill them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:56.111399Z",
     "start_time": "2018-06-07T00:19:56.090505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_images</th>\n",
       "      <th>longueur_image</th>\n",
       "      <th>largeur_image</th>\n",
       "      <th>etat</th>\n",
       "      <th>vintage</th>\n",
       "      <th>poids</th>\n",
       "      <th>prix</th>\n",
       "      <th>categorie</th>\n",
       "      <th>sous_categorie_1</th>\n",
       "      <th>nom_magasin</th>\n",
       "      <th>description_car</th>\n",
       "      <th>description_wor</th>\n",
       "      <th>nom_car</th>\n",
       "      <th>nom_wor</th>\n",
       "      <th>description_sentiment</th>\n",
       "      <th>description_subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>2552.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>mode</td>\n",
       "      <td>tops, t-shirts, débardeurs femme</td>\n",
       "      <td>Emmaüs 88 Neufchateau</td>\n",
       "      <td>191</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.388333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2486.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>mobilier - deco</td>\n",
       "      <td>bibelots et objets déco</td>\n",
       "      <td>Communauté Emmaüs Thouars (magasin Parthenay)</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>label selection</td>\n",
       "      <td>mode</td>\n",
       "      <td>Label Emmaüs Chambéry</td>\n",
       "      <td>182</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>mobilier - deco</td>\n",
       "      <td>autres objets</td>\n",
       "      <td>Emmaüs Lyon</td>\n",
       "      <td>228</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>450.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>multimédia</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>La Bootique des Ateliers du Bocage</td>\n",
       "      <td>592</td>\n",
       "      <td>103</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>0.185556</td>\n",
       "      <td>0.294444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_images  longueur_image  largeur_image  etat  vintage   poids   prix  \\\n",
       "id                                                                           \n",
       "0           3          3458.0         2552.0   1.0        0   200.0    4.5   \n",
       "1           2          2486.0         2254.0   0.0        1  1000.0   15.0   \n",
       "2           3          1536.0         1536.0   4.0        0   360.0   16.0   \n",
       "3           2          1100.0         1100.0   1.0        0   520.0   24.0   \n",
       "4           2           450.0          450.0   2.0        0   300.0  139.0   \n",
       "\n",
       "          categorie                  sous_categorie_1  \\\n",
       "id                                                      \n",
       "0              mode  tops, t-shirts, débardeurs femme   \n",
       "1   mobilier - deco           bibelots et objets déco   \n",
       "2   label selection                              mode   \n",
       "3   mobilier - deco                     autres objets   \n",
       "4        multimédia                       smartphones   \n",
       "\n",
       "                                      nom_magasin  description_car  \\\n",
       "id                                                                   \n",
       "0                           Emmaüs 88 Neufchateau              191   \n",
       "1   Communauté Emmaüs Thouars (magasin Parthenay)               42   \n",
       "2                           Label Emmaüs Chambéry              182   \n",
       "3                                     Emmaüs Lyon              228   \n",
       "4              La Bootique des Ateliers du Bocage              592   \n",
       "\n",
       "    description_wor  nom_car  nom_wor  description_sentiment  \\\n",
       "id                                                             \n",
       "0                36       24        3               0.396667   \n",
       "1                 8       17        3               0.000000   \n",
       "2                29        0        0               0.005000   \n",
       "3                38       24        4               0.008000   \n",
       "4               103       49       10               0.185556   \n",
       "\n",
       "    description_subjectivity  \n",
       "id                            \n",
       "0                   0.388333  \n",
       "1                   0.000000  \n",
       "2                   0.300000  \n",
       "3                   0.160000  \n",
       "4                   0.294444  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:56.135167Z",
     "start_time": "2018-06-07T00:19:56.113636Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_images                      0\n",
      "longueur_image                39\n",
      "largeur_image                 39\n",
      "etat                          19\n",
      "vintage                        0\n",
      "poids                          2\n",
      "prix                           0\n",
      "categorie                      1\n",
      "sous_categorie_1            1099\n",
      "nom_magasin                    0\n",
      "description_car                0\n",
      "description_wor                0\n",
      "nom_car                        0\n",
      "nom_wor                        0\n",
      "description_sentiment          0\n",
      "description_subjectivity       0\n",
      "dtype: int64\n",
      "nb_images                     0\n",
      "longueur_image               18\n",
      "largeur_image                18\n",
      "etat                          5\n",
      "vintage                       0\n",
      "poids                         0\n",
      "prix                          0\n",
      "categorie                     0\n",
      "sous_categorie_1            489\n",
      "nom_magasin                   0\n",
      "description_car               0\n",
      "description_wor               0\n",
      "nom_car                       0\n",
      "nom_wor                       0\n",
      "description_sentiment         0\n",
      "description_subjectivity      0\n",
      "dtype: int64\n",
      "nb_images                      0\n",
      "longueur_image                57\n",
      "largeur_image                 57\n",
      "etat                          24\n",
      "vintage                        0\n",
      "poids                          2\n",
      "prix                           0\n",
      "categorie                      1\n",
      "sous_categorie_1            1588\n",
      "nom_magasin                    0\n",
      "description_car                0\n",
      "description_wor                0\n",
      "nom_car                        0\n",
      "nom_wor                        0\n",
      "description_sentiment          0\n",
      "description_subjectivity       0\n",
      "dtype: int64\n",
      "nb_images                     0\n",
      "longueur_image               13\n",
      "largeur_image                13\n",
      "etat                          3\n",
      "vintage                       0\n",
      "poids                         2\n",
      "prix                          0\n",
      "categorie                     4\n",
      "sous_categorie_1            548\n",
      "nom_magasin                   0\n",
      "description_car               0\n",
      "description_wor               0\n",
      "nom_car                       0\n",
      "nom_wor                       0\n",
      "description_sentiment         0\n",
      "description_subjectivity      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_train.isnull().sum())\n",
    "print(x_val.isnull().sum())\n",
    "print(X_train.isnull().sum())\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the missing numerical features, we fill with the mean of the training set. For the categorical, we create a new categorie ('missing'). This new categorie can bring informations. <br>\n",
    "We care about not using unseen data to fill the NaN. So we don't use x_val to compute the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:57.484180Z",
     "start_time": "2018-06-07T00:19:57.445552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806.7830662133722\n",
      "1796.1892504451998\n",
      "6853.413809140649\n",
      "nb_images                      0\n",
      "longueur_image                 0\n",
      "largeur_image                  0\n",
      "etat                           0\n",
      "vintage                        0\n",
      "poids                          0\n",
      "prix                           0\n",
      "categorie                      1\n",
      "sous_categorie_1            1099\n",
      "nom_magasin                    0\n",
      "description_car                0\n",
      "description_wor                0\n",
      "nom_car                        0\n",
      "nom_wor                        0\n",
      "description_sentiment          0\n",
      "description_subjectivity       0\n",
      "dtype: int64\n",
      "nb_images                     0\n",
      "longueur_image                0\n",
      "largeur_image                 0\n",
      "etat                          0\n",
      "vintage                       0\n",
      "poids                         0\n",
      "prix                          0\n",
      "categorie                     0\n",
      "sous_categorie_1            489\n",
      "nom_magasin                   0\n",
      "description_car               0\n",
      "description_wor               0\n",
      "nom_car                       0\n",
      "nom_wor                       0\n",
      "description_sentiment         0\n",
      "description_subjectivity      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mean_longueur_image = np.mean(x_train.longueur_image)\n",
    "print(mean_longueur_image)\n",
    "mean_largeur_image = np.mean(x_train.largeur_image)\n",
    "print(mean_largeur_image)\n",
    "mean_poids = np.mean(x_train.poids)\n",
    "print(mean_poids)\n",
    "\n",
    "\n",
    "x_train.longueur_image.fillna(mean_longueur_image, inplace=True)\n",
    "x_train.largeur_image.fillna(mean_largeur_image, inplace=True)\n",
    "x_train.poids.fillna(mean_poids, inplace=True)\n",
    "\n",
    "x_val.longueur_image.fillna(mean_longueur_image, inplace=True)\n",
    "x_val.largeur_image.fillna(mean_largeur_image, inplace=True)\n",
    "x_val.poids.fillna(mean_poids, inplace=True)\n",
    "\n",
    "# for etat, we fill with an average value of 2. etat is ordered categorical so we can consider as numerical.\n",
    "\n",
    "x_train.etat.fillna(2, inplace=True)\n",
    "\n",
    "x_val.etat.fillna(2, inplace=True)\n",
    "\n",
    "\n",
    "print(x_train.isnull().sum())\n",
    "print(x_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:58.194869Z",
     "start_time": "2018-06-07T00:19:58.187651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1807.82126260909\n",
      "1801.773433072651\n",
      "7794.864492903808\n"
     ]
    }
   ],
   "source": [
    "# I am taking these ones for later when we'll use the whole X_train as training dataset\n",
    "\n",
    "\n",
    "w_mean_longueur_image = np.mean(X_train.longueur_image)\n",
    "print(w_mean_longueur_image)\n",
    "w_mean_largeur_image = np.mean(X_train.largeur_image)\n",
    "print(w_mean_largeur_image)\n",
    "w_mean_poids = np.mean(X_train.poids)\n",
    "print(w_mean_poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:58.901250Z",
     "start_time": "2018-06-07T00:19:58.875429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_images                      0\n",
      "longueur_image                 0\n",
      "largeur_image                  0\n",
      "etat                           0\n",
      "vintage                        0\n",
      "poids                          0\n",
      "prix                           0\n",
      "categorie                      1\n",
      "sous_categorie_1            1588\n",
      "nom_magasin                    0\n",
      "description_car                0\n",
      "description_wor                0\n",
      "nom_car                        0\n",
      "nom_wor                        0\n",
      "description_sentiment          0\n",
      "description_subjectivity       0\n",
      "dtype: int64\n",
      "nb_images                     0\n",
      "longueur_image                0\n",
      "largeur_image                 0\n",
      "etat                          0\n",
      "vintage                       0\n",
      "poids                         0\n",
      "prix                          0\n",
      "categorie                     4\n",
      "sous_categorie_1            548\n",
      "nom_magasin                   0\n",
      "description_car               0\n",
      "description_wor               0\n",
      "nom_car                       0\n",
      "nom_wor                       0\n",
      "description_sentiment         0\n",
      "description_subjectivity      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train.longueur_image.fillna(w_mean_longueur_image, inplace=True)\n",
    "X_train.largeur_image.fillna(w_mean_largeur_image, inplace=True)\n",
    "X_train.poids.fillna(w_mean_poids, inplace=True)\n",
    "\n",
    "X_test.longueur_image.fillna(w_mean_longueur_image, inplace=True)\n",
    "X_test.largeur_image.fillna(w_mean_largeur_image, inplace=True)\n",
    "X_test.poids.fillna(w_mean_poids, inplace=True)\n",
    "\n",
    "\n",
    "X_train.etat.fillna(2, inplace=True)\n",
    "\n",
    "X_test.etat.fillna(2, inplace=True)\n",
    "\n",
    "print(X_train.isnull().sum())\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining missing values are only categorical, let's fill them with the 'missing categorie'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:19:59.612018Z",
     "start_time": "2018-06-07T00:19:59.581612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train.fillna('missing', inplace=True)\n",
    "x_train.fillna('missing', inplace=True)\n",
    "x_val.fillna('missing', inplace=True)\n",
    "X_test.fillna('missing', inplace=True)\n",
    "\n",
    "print(x_train.isnull().sum().sum())\n",
    "print(x_val.isnull().sum().sum())\n",
    "\n",
    "print(X_train.isnull().sum().sum())\n",
    "print(X_test.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no NaN values anymore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding creates dummies variables in order to represent each category (for the non-ordered ones). The method is already implemented in Pandas. However, there is one problem. Sometime, a category can be present in training set and not in testing set. Then, it results in two datasets with different columns. Let's use this amazing trick posted by Artem Golubin. (https://github.com/rushter/heamy/blob/master/heamy/feature.py#L7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: I modified the original code to drop the first column of dummies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:20:00.620352Z",
     "start_time": "2018-06-07T00:20:00.578879Z"
    }
   },
   "outputs": [],
   "source": [
    "def onehot_features(train, test, features, full=False, sparse=False, dummy_na=True):\n",
    "    \"\"\"Encode categorical features using a one-hot scheme.\n",
    "    Parameters\n",
    "    ----------\n",
    "    train : pd.DataFrame\n",
    "    test : pd.DataFrame\n",
    "    features : list\n",
    "        Column names in the DataFrame to be encoded.\n",
    "    full : bool, default False\n",
    "        Whether use all columns from train/test or only from train.\n",
    "    sparse : bool, default False\n",
    "        Whether the dummy columns should be sparse or not.\n",
    "    dummy_na : bool, default True\n",
    "        Add a column to indicate NaNs, if False NaNs are ignored.\n",
    "    Returns\n",
    "    -------\n",
    "    train : pd.DataFrame\n",
    "    test : pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    features = [f for f in features if f in train.columns]\n",
    "    for column in features:\n",
    "        if full:\n",
    "            categories = pd.concat(\n",
    "                [train[column], test[column]]).dropna().unique()\n",
    "        else:\n",
    "            categories = train[column].dropna().unique()\n",
    "\n",
    "        train[column] = train[column].astype('category', categories=categories)\n",
    "        test[column] = test[column].astype('category', categories=categories)\n",
    "\n",
    "    train = pd.get_dummies(train, columns=features,\n",
    "                           dummy_na=dummy_na, sparse=sparse, drop_first=True)\n",
    "    test = pd.get_dummies(test, columns=features,\n",
    "                          dummy_na=dummy_na, sparse=sparse, drop_first=True)\n",
    "\n",
    "    # d_cols = train.columns[(train == 0).all()]\n",
    "    # train.drop(d_cols, 1, inplace=True)\n",
    "    # test.drop(d_cols, 1, inplace=True)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:20:01.771027Z",
     "start_time": "2018-06-07T00:20:01.766689Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = ['categorie', 'sous_categorie_1', 'nom_magasin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:20:02.556727Z",
     "start_time": "2018-06-07T00:20:02.475802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Selim/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "/Users/Selim/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val = onehot_features(\n",
    "    x_train, x_val, cat_features, full=False, sparse=False, dummy_na=False)\n",
    "X_train, X_test = onehot_features(\n",
    "    X_train, X_test, cat_features, full=False, sparse=False, dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:20:07.710528Z",
     "start_time": "2018-06-07T00:20:07.530287Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_images</th>\n",
       "      <th>longueur_image</th>\n",
       "      <th>largeur_image</th>\n",
       "      <th>etat</th>\n",
       "      <th>vintage</th>\n",
       "      <th>poids</th>\n",
       "      <th>prix</th>\n",
       "      <th>description_car</th>\n",
       "      <th>description_wor</th>\n",
       "      <th>nom_car</th>\n",
       "      <th>nom_wor</th>\n",
       "      <th>description_sentiment</th>\n",
       "      <th>description_subjectivity</th>\n",
       "      <th>categorie_loisirs</th>\n",
       "      <th>categorie_mobilier - deco</th>\n",
       "      <th>categorie_librairie</th>\n",
       "      <th>categorie_label selection</th>\n",
       "      <th>categorie_enfance</th>\n",
       "      <th>categorie_multimédia</th>\n",
       "      <th>categorie_culture - loisirs</th>\n",
       "      <th>categorie_les coups de coeur des vendeurs</th>\n",
       "      <th>categorie_créations</th>\n",
       "      <th>categorie_missing</th>\n",
       "      <th>sous_categorie_1_mobilier - deco</th>\n",
       "      <th>sous_categorie_1_Vases et Pots</th>\n",
       "      <th>sous_categorie_1_missing</th>\n",
       "      <th>sous_categorie_1_autres objets</th>\n",
       "      <th>sous_categorie_1_bijoux et montres</th>\n",
       "      <th>sous_categorie_1_label selection</th>\n",
       "      <th>sous_categorie_1_accessoires femme</th>\n",
       "      <th>sous_categorie_1_mode</th>\n",
       "      <th>sous_categorie_1_bibelots et objets déco</th>\n",
       "      <th>sous_categorie_1_objets d'art, antiquités</th>\n",
       "      <th>sous_categorie_1_Saint Valentin</th>\n",
       "      <th>sous_categorie_1_mode femme</th>\n",
       "      <th>sous_categorie_1_héros, figurines</th>\n",
       "      <th>sous_categorie_1_tableaux, miroirs, déco murale</th>\n",
       "      <th>sous_categorie_1_pantalons homme</th>\n",
       "      <th>sous_categorie_1_enfance</th>\n",
       "      <th>sous_categorie_1_manteaux, blousons femme</th>\n",
       "      <th>sous_categorie_1_gilets, pulls femme</th>\n",
       "      <th>sous_categorie_1_vêtements fille 6 - 12 ans</th>\n",
       "      <th>sous_categorie_1_pantalons femme</th>\n",
       "      <th>sous_categorie_1_chaussures et bottes femme</th>\n",
       "      <th>sous_categorie_1_Pub et Réclame</th>\n",
       "      <th>sous_categorie_1_chaussures et bottes homme</th>\n",
       "      <th>sous_categorie_1_vestes, blazers femme</th>\n",
       "      <th>sous_categorie_1_jeux de société, puzzles</th>\n",
       "      <th>sous_categorie_1_chemisiers, blouses, tuniques femme</th>\n",
       "      <th>sous_categorie_1_sacs, maroquinerie</th>\n",
       "      <th>sous_categorie_1_romans, livres poche, nouvelles</th>\n",
       "      <th>sous_categorie_1_vinyles</th>\n",
       "      <th>sous_categorie_1_jupes, shorts femme</th>\n",
       "      <th>sous_categorie_1_tricot, crochet</th>\n",
       "      <th>sous_categorie_1_littérature jeunesse</th>\n",
       "      <th>sous_categorie_1_objets déco et vaisselle</th>\n",
       "      <th>sous_categorie_1_DVDs</th>\n",
       "      <th>sous_categorie_1_tops, t-shirts, débardeurs femme</th>\n",
       "      <th>sous_categorie_1_luminaires</th>\n",
       "      <th>sous_categorie_1_services de vaisselle, vaisselle en lots</th>\n",
       "      <th>sous_categorie_1_linge de maison</th>\n",
       "      <th>sous_categorie_1_loisirs</th>\n",
       "      <th>sous_categorie_1_gilets, pulls homme</th>\n",
       "      <th>sous_categorie_1_platines et radios</th>\n",
       "      <th>sous_categorie_1_ordinateurs de bureau</th>\n",
       "      <th>sous_categorie_1_vaisselle à l'unité</th>\n",
       "      <th>sous_categorie_1_librairie</th>\n",
       "      <th>sous_categorie_1_accessoires homme</th>\n",
       "      <th>sous_categorie_1_Cartes postales</th>\n",
       "      <th>sous_categorie_1_chemises, polos homme</th>\n",
       "      <th>sous_categorie_1_véhicules</th>\n",
       "      <th>sous_categorie_1_accessoires et maroquinerie</th>\n",
       "      <th>sous_categorie_1_Romans de Gare</th>\n",
       "      <th>sous_categorie_1_manteaux, blousons homme</th>\n",
       "      <th>sous_categorie_1_Maillots de bain</th>\n",
       "      <th>sous_categorie_1_rangements, étagères, escabeaux</th>\n",
       "      <th>sous_categorie_1_chaises, tabourets</th>\n",
       "      <th>sous_categorie_1_image et son</th>\n",
       "      <th>sous_categorie_1_poupées</th>\n",
       "      <th>sous_categorie_1_BD et mangas</th>\n",
       "      <th>sous_categorie_1_appareils photo et accessoires photo</th>\n",
       "      <th>sous_categorie_1_autres jouets</th>\n",
       "      <th>sous_categorie_1_chaussures</th>\n",
       "      <th>sous_categorie_1_périphériques et accessoires</th>\n",
       "      <th>sous_categorie_1_Les héros des plus grands</th>\n",
       "      <th>sous_categorie_1_culture - loisirs</th>\n",
       "      <th>sous_categorie_1_jeux et jouets</th>\n",
       "      <th>sous_categorie_1_A carreaux !</th>\n",
       "      <th>sous_categorie_1_Vêtements été</th>\n",
       "      <th>sous_categorie_1_mode homme</th>\n",
       "      <th>sous_categorie_1_vestes, blazers homme</th>\n",
       "      <th>sous_categorie_1_vie pratique, loisirs</th>\n",
       "      <th>sous_categorie_1_jouets anciens, jouets en bois</th>\n",
       "      <th>sous_categorie_1_multimédia</th>\n",
       "      <th>sous_categorie_1_La Petite robe noire</th>\n",
       "      <th>sous_categorie_1_Label Affaire ! (braderie à - de 10€)</th>\n",
       "      <th>sous_categorie_1_layette naissance - 18 mois</th>\n",
       "      <th>sous_categorie_1_jeux vidéos et consoles</th>\n",
       "      <th>sous_categorie_1_smartphones</th>\n",
       "      <th>sous_categorie_1_vélos</th>\n",
       "      <th>sous_categorie_1_vêtements garçon 6 - 12 ans</th>\n",
       "      <th>sous_categorie_1_t-shirts, débardeurs homme</th>\n",
       "      <th>sous_categorie_1_sport</th>\n",
       "      <th>sous_categorie_1_fournitures et papeterie</th>\n",
       "      <th>sous_categorie_1_Le Ski</th>\n",
       "      <th>sous_categorie_1_ensembles, combinaisons, tailleurs femme</th>\n",
       "      <th>sous_categorie_1_instruments de musique</th>\n",
       "      <th>sous_categorie_1_livres d'images, livres enfants</th>\n",
       "      <th>sous_categorie_1_commodes, chevets, chiffonniers</th>\n",
       "      <th>sous_categorie_1_livres anciens</th>\n",
       "      <th>sous_categorie_1_Horloges, Pendules, Réveils</th>\n",
       "      <th>sous_categorie_1_machines à coudre, travailleuses, couturières</th>\n",
       "      <th>sous_categorie_1_vêtements bébé, enfant, ado</th>\n",
       "      <th>sous_categorie_1_Les héros des petits</th>\n",
       "      <th>sous_categorie_1_les coups de coeur des vendeurs</th>\n",
       "      <th>sous_categorie_1_vêtements ados</th>\n",
       "      <th>sous_categorie_1_Esprit Vintage</th>\n",
       "      <th>sous_categorie_1_CDs</th>\n",
       "      <th>sous_categorie_1_matériel et accessoires de sport</th>\n",
       "      <th>sous_categorie_1_Séries ado - Young Adult</th>\n",
       "      <th>sous_categorie_1_tissu, coupons, petite mercerie, accessoires couture</th>\n",
       "      <th>sous_categorie_1_littérature étrangère</th>\n",
       "      <th>sous_categorie_1_vêtements de sport femme</th>\n",
       "      <th>sous_categorie_1_platines et transistors</th>\n",
       "      <th>sous_categorie_1_écrans</th>\n",
       "      <th>sous_categorie_1_fauteuils, poufs</th>\n",
       "      <th>sous_categorie_1_Cabinet de curiosités</th>\n",
       "      <th>sous_categorie_1_vêtements garçon 2 - 6 ans</th>\n",
       "      <th>sous_categorie_1_Shorts, Bermudas, Maillots de bain Homme</th>\n",
       "      <th>sous_categorie_1_Le Cuir</th>\n",
       "      <th>sous_categorie_1_revues, magazines</th>\n",
       "      <th>sous_categorie_1_playmobil, LEGO, Mécano</th>\n",
       "      <th>sous_categorie_1_Tous sur notre 31 !</th>\n",
       "      <th>sous_categorie_1_partitions</th>\n",
       "      <th>sous_categorie_1_vêtements de sport homme</th>\n",
       "      <th>sous_categorie_1_accessoires enfant</th>\n",
       "      <th>sous_categorie_1_costumes homme</th>\n",
       "      <th>sous_categorie_1_poussettes, couffins</th>\n",
       "      <th>sous_categorie_1_Vêtements Printemps</th>\n",
       "      <th>sous_categorie_1_Livres à moins de 5€</th>\n",
       "      <th>sous_categorie_1_Vêtements Vintage Femme</th>\n",
       "      <th>sous_categorie_1_Cérémonies</th>\n",
       "      <th>sous_categorie_1_Label Fashion Week</th>\n",
       "      <th>sous_categorie_1_Déco Vintage</th>\n",
       "      <th>sous_categorie_1_collections, cartes postales, timbres, monnaie, vieux papiers</th>\n",
       "      <th>sous_categorie_1_rollers, skateboards, trotinettes</th>\n",
       "      <th>sous_categorie_1_objets régionaux</th>\n",
       "      <th>sous_categorie_1_vêtements fille 2 - 6 ans</th>\n",
       "      <th>sous_categorie_1_poésie, théâtre</th>\n",
       "      <th>sous_categorie_1_Déco Romantique</th>\n",
       "      <th>sous_categorie_1_accessoires de puériculture</th>\n",
       "      <th>sous_categorie_1_bricolage</th>\n",
       "      <th>sous_categorie_1_créations</th>\n",
       "      <th>sous_categorie_1_livres scolaires</th>\n",
       "      <th>sous_categorie_1_Tenues de cérémonie</th>\n",
       "      <th>sous_categorie_1_canapés, banquettes, bancs</th>\n",
       "      <th>sous_categorie_1_vêtements de sport enfant</th>\n",
       "      <th>sous_categorie_1_buffets, enfilades</th>\n",
       "      <th>sous_categorie_1_armoires, vitrines, bibliothèques</th>\n",
       "      <th>sous_categorie_1_jeux d'éveil</th>\n",
       "      <th>sous_categorie_1_On continue, l'abbé !</th>\n",
       "      <th>sous_categorie_1_Déco Couleurs Naturelles et Doré</th>\n",
       "      <th>sous_categorie_1_petit mobilier</th>\n",
       "      <th>sous_categorie_1_loisirs créatifs, couture, mercerie, déguisements</th>\n",
       "      <th>sous_categorie_1_culture, société, voyages</th>\n",
       "      <th>sous_categorie_1_chaussures enfant</th>\n",
       "      <th>sous_categorie_1_tapis</th>\n",
       "      <th>sous_categorie_1_Journée de la femme</th>\n",
       "      <th>sous_categorie_1_déguisements</th>\n",
       "      <th>sous_categorie_1_ordinateurs portables</th>\n",
       "      <th>sous_categorie_1_Noël</th>\n",
       "      <th>sous_categorie_1_mobiles</th>\n",
       "      <th>sous_categorie_1_gros mobilier</th>\n",
       "      <th>sous_categorie_1_dentelles</th>\n",
       "      <th>sous_categorie_1_Denim pour tous !</th>\n",
       "      <th>sous_categorie_1_Fête de la musique</th>\n",
       "      <th>sous_categorie_1_tables et bureaux</th>\n",
       "      <th>sous_categorie_1_meubles de métier</th>\n",
       "      <th>sous_categorie_1_imprimantes</th>\n",
       "      <th>sous_categorie_1_Déco Kitsch</th>\n",
       "      <th>sous_categorie_1_Métiers d'hier</th>\n",
       "      <th>sous_categorie_1_Vélorution !</th>\n",
       "      <th>sous_categorie_1_tablettes</th>\n",
       "      <th>sous_categorie_1_Shabby Chic</th>\n",
       "      <th>sous_categorie_1_Enfin le printemps !</th>\n",
       "      <th>nom_magasin_Emmaüs 88 Neufchateau</th>\n",
       "      <th>nom_magasin_Frip'Insertion Marseille Libération</th>\n",
       "      <th>nom_magasin_Booki - la Librairie Solidaire de Retrilog</th>\n",
       "      <th>nom_magasin_Emmaüs Lyon</th>\n",
       "      <th>nom_magasin_Label Emmaüs Chambéry</th>\n",
       "      <th>nom_magasin_Le Léopard</th>\n",
       "      <th>nom_magasin_Labelemmaus Vendée</th>\n",
       "      <th>nom_magasin_Emmaüs Avenir Neuilly sur Marne</th>\n",
       "      <th>nom_magasin_Emmaüs Sacré Dressing !</th>\n",
       "      <th>nom_magasin_ADBook - la Librairie Solidaire des Ateliers du Bocage</th>\n",
       "      <th>nom_magasin_Label Emmaüs de Grenoble</th>\n",
       "      <th>nom_magasin_La Boutique Emmaüs d’Auray</th>\n",
       "      <th>nom_magasin_Communauté Emmaüs Thouars (magasin Parthenay)</th>\n",
       "      <th>nom_magasin_Frip'Attitude Emmaüs Vêtement</th>\n",
       "      <th>nom_magasin_Emmaüs Saintes Saint Romain</th>\n",
       "      <th>nom_magasin_La Boutique Emmaüs de Lorient Plénéno</th>\n",
       "      <th>nom_magasin_Label Emmaus Angers</th>\n",
       "      <th>nom_magasin_Emmaüs Liberté Ivry</th>\n",
       "      <th>nom_magasin_Ding Fring – En mode solidaire</th>\n",
       "      <th>nom_magasin_Emmaüs Vannes - la Boutique en ligne</th>\n",
       "      <th>nom_magasin_Comité d'amis Emmaüs Roanne Mably</th>\n",
       "      <th>nom_magasin_Communauté Emmaüs Soissons</th>\n",
       "      <th>nom_magasin_Emmaüs Indre Le Blanc</th>\n",
       "      <th>nom_magasin_Emmaüs Défi 104</th>\n",
       "      <th>nom_magasin_Comité d'amis Emmaüs Millau</th>\n",
       "      <th>nom_magasin_Emmaüs St Etienne - Firminy</th>\n",
       "      <th>nom_magasin_Comité d'amis Emmaüs Pont Audemer</th>\n",
       "      <th>nom_magasin_La Boutique Emmaüs Pontivy</th>\n",
       "      <th>nom_magasin_Emmaus Chenôve</th>\n",
       "      <th>nom_magasin_La Bootique des Ateliers du Bocage</th>\n",
       "      <th>nom_magasin_Emmaüs Alternatives Sélection</th>\n",
       "      <th>nom_magasin_Le coin de l'e-chineur</th>\n",
       "      <th>nom_magasin_Comité d'amis Emmaüs Beauvais</th>\n",
       "      <th>nom_magasin_L'Abri 88</th>\n",
       "      <th>nom_magasin_Tri Rhône-Alpes - la Boutique en ligne</th>\n",
       "      <th>nom_magasin_Communauté Emmaüs Angoulême</th>\n",
       "      <th>nom_magasin_Ding Fring - En page solidaire</th>\n",
       "      <th>nom_magasin_Emmaüs Mobilier Pro</th>\n",
       "      <th>nom_magasin_Comité d'amis Emmaüs Ruffec</th>\n",
       "      <th>nom_magasin_Atelier Emmaüs</th>\n",
       "      <th>nom_magasin_La Boutique militante : Article 13</th>\n",
       "      <th>nom_magasin_Librairie Colibrio</th>\n",
       "      <th>nom_magasin_Communauté Emmaüs Thouars</th>\n",
       "      <th>nom_magasin_Boutique des amis d'Emmaüs Apt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>3</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>130</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528</th>\n",
       "      <td>5</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>2287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>366</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>5</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>135</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>1</td>\n",
       "      <td>616.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>858</td>\n",
       "      <td>117</td>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "      <td>0.101429</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>2</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>196</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_images  longueur_image  largeur_image  etat  vintage   poids  prix  \\\n",
       "id                                                                            \n",
       "5540          3          1600.0          900.0   4.0        0   500.0   7.0   \n",
       "5528          5          2450.0         2287.0   1.0        1  3400.0  30.0   \n",
       "3434          5          2200.0         2200.0   1.0        0  1300.0   6.0   \n",
       "5621          1           616.0          616.0   0.0        0   120.0   2.0   \n",
       "5267          2          1100.0         1100.0   1.0        1  1000.0  30.0   \n",
       "\n",
       "      description_car  description_wor  nom_car  nom_wor  \\\n",
       "id                                                         \n",
       "5540              130               13       22        6   \n",
       "5528              366               73       29        3   \n",
       "3434              135               24       36        7   \n",
       "5621              858              117       52        8   \n",
       "5267              196               31       24        3   \n",
       "\n",
       "      description_sentiment  description_subjectivity  categorie_loisirs  \\\n",
       "id                                                                         \n",
       "5540               0.000000                  0.000000                  0   \n",
       "5528               0.200000                  0.133333                  1   \n",
       "3434              -0.010000                  0.066667                  0   \n",
       "5621               0.101429                  0.328571                  0   \n",
       "5267               0.168000                  0.240000                  0   \n",
       "\n",
       "      categorie_mobilier - deco  categorie_librairie  \\\n",
       "id                                                     \n",
       "5540                          0                    0   \n",
       "5528                          0                    0   \n",
       "3434                          1                    0   \n",
       "5621                          0                    1   \n",
       "5267                          1                    0   \n",
       "\n",
       "      categorie_label selection  categorie_enfance  categorie_multimédia  \\\n",
       "id                                                                         \n",
       "5540                          0                  0                     0   \n",
       "5528                          0                  0                     0   \n",
       "3434                          0                  0                     0   \n",
       "5621                          0                  0                     0   \n",
       "5267                          0                  0                     0   \n",
       "\n",
       "      categorie_culture - loisirs  categorie_les coups de coeur des vendeurs  \\\n",
       "id                                                                             \n",
       "5540                            0                                          0   \n",
       "5528                            0                                          0   \n",
       "3434                            0                                          0   \n",
       "5621                            0                                          0   \n",
       "5267                            0                                          0   \n",
       "\n",
       "      categorie_créations  categorie_missing  \\\n",
       "id                                             \n",
       "5540                    0                  0   \n",
       "5528                    0                  0   \n",
       "3434                    0                  0   \n",
       "5621                    0                  0   \n",
       "5267                    0                  0   \n",
       "\n",
       "      sous_categorie_1_mobilier - deco  sous_categorie_1_Vases et Pots  \\\n",
       "id                                                                       \n",
       "5540                                 0                               0   \n",
       "5528                                 1                               0   \n",
       "3434                                 0                               1   \n",
       "5621                                 0                               0   \n",
       "5267                                 0                               0   \n",
       "\n",
       "      sous_categorie_1_missing  sous_categorie_1_autres objets  \\\n",
       "id                                                               \n",
       "5540                         0                               0   \n",
       "5528                         0                               0   \n",
       "3434                         0                               0   \n",
       "5621                         1                               0   \n",
       "5267                         0                               1   \n",
       "\n",
       "      sous_categorie_1_bijoux et montres  sous_categorie_1_label selection  \\\n",
       "id                                                                           \n",
       "5540                                   0                                 0   \n",
       "5528                                   0                                 0   \n",
       "3434                                   0                                 0   \n",
       "5621                                   0                                 0   \n",
       "5267                                   0                                 0   \n",
       "\n",
       "      sous_categorie_1_accessoires femme  sous_categorie_1_mode  \\\n",
       "id                                                                \n",
       "5540                                   0                      0   \n",
       "5528                                   0                      0   \n",
       "3434                                   0                      0   \n",
       "5621                                   0                      0   \n",
       "5267                                   0                      0   \n",
       "\n",
       "      sous_categorie_1_bibelots et objets déco  \\\n",
       "id                                               \n",
       "5540                                         0   \n",
       "5528                                         0   \n",
       "3434                                         0   \n",
       "5621                                         0   \n",
       "5267                                         0   \n",
       "\n",
       "      sous_categorie_1_objets d'art, antiquités  \\\n",
       "id                                                \n",
       "5540                                          0   \n",
       "5528                                          0   \n",
       "3434                                          0   \n",
       "5621                                          0   \n",
       "5267                                          0   \n",
       "\n",
       "      sous_categorie_1_Saint Valentin  sous_categorie_1_mode femme  \\\n",
       "id                                                                   \n",
       "5540                                0                            0   \n",
       "5528                                0                            0   \n",
       "3434                                0                            0   \n",
       "5621                                0                            0   \n",
       "5267                                0                            0   \n",
       "\n",
       "      sous_categorie_1_héros, figurines  \\\n",
       "id                                        \n",
       "5540                                  0   \n",
       "5528                                  0   \n",
       "3434                                  0   \n",
       "5621                                  0   \n",
       "5267                                  0   \n",
       "\n",
       "      sous_categorie_1_tableaux, miroirs, déco murale  \\\n",
       "id                                                      \n",
       "5540                                                0   \n",
       "5528                                                0   \n",
       "3434                                                0   \n",
       "5621                                                0   \n",
       "5267                                                0   \n",
       "\n",
       "      sous_categorie_1_pantalons homme  sous_categorie_1_enfance  \\\n",
       "id                                                                 \n",
       "5540                                 0                         0   \n",
       "5528                                 0                         0   \n",
       "3434                                 0                         0   \n",
       "5621                                 0                         0   \n",
       "5267                                 0                         0   \n",
       "\n",
       "      sous_categorie_1_manteaux, blousons femme  \\\n",
       "id                                                \n",
       "5540                                          0   \n",
       "5528                                          0   \n",
       "3434                                          0   \n",
       "5621                                          0   \n",
       "5267                                          0   \n",
       "\n",
       "      sous_categorie_1_gilets, pulls femme  \\\n",
       "id                                           \n",
       "5540                                     0   \n",
       "5528                                     0   \n",
       "3434                                     0   \n",
       "5621                                     0   \n",
       "5267                                     0   \n",
       "\n",
       "      sous_categorie_1_vêtements fille 6 - 12 ans  \\\n",
       "id                                                  \n",
       "5540                                            0   \n",
       "5528                                            0   \n",
       "3434                                            0   \n",
       "5621                                            0   \n",
       "5267                                            0   \n",
       "\n",
       "      sous_categorie_1_pantalons femme  \\\n",
       "id                                       \n",
       "5540                                 0   \n",
       "5528                                 0   \n",
       "3434                                 0   \n",
       "5621                                 0   \n",
       "5267                                 0   \n",
       "\n",
       "      sous_categorie_1_chaussures et bottes femme  \\\n",
       "id                                                  \n",
       "5540                                            0   \n",
       "5528                                            0   \n",
       "3434                                            0   \n",
       "5621                                            0   \n",
       "5267                                            0   \n",
       "\n",
       "      sous_categorie_1_Pub et Réclame  \\\n",
       "id                                      \n",
       "5540                                0   \n",
       "5528                                0   \n",
       "3434                                0   \n",
       "5621                                0   \n",
       "5267                                0   \n",
       "\n",
       "      sous_categorie_1_chaussures et bottes homme  \\\n",
       "id                                                  \n",
       "5540                                            0   \n",
       "5528                                            0   \n",
       "3434                                            0   \n",
       "5621                                            0   \n",
       "5267                                            0   \n",
       "\n",
       "      sous_categorie_1_vestes, blazers femme  \\\n",
       "id                                             \n",
       "5540                                       0   \n",
       "5528                                       0   \n",
       "3434                                       0   \n",
       "5621                                       0   \n",
       "5267                                       0   \n",
       "\n",
       "      sous_categorie_1_jeux de société, puzzles  \\\n",
       "id                                                \n",
       "5540                                          0   \n",
       "5528                                          0   \n",
       "3434                                          0   \n",
       "5621                                          0   \n",
       "5267                                          0   \n",
       "\n",
       "      sous_categorie_1_chemisiers, blouses, tuniques femme  \\\n",
       "id                                                           \n",
       "5540                                                  0      \n",
       "5528                                                  0      \n",
       "3434                                                  0      \n",
       "5621                                                  0      \n",
       "5267                                                  0      \n",
       "\n",
       "      sous_categorie_1_sacs, maroquinerie  \\\n",
       "id                                          \n",
       "5540                                    0   \n",
       "5528                                    0   \n",
       "3434                                    0   \n",
       "5621                                    0   \n",
       "5267                                    0   \n",
       "\n",
       "      sous_categorie_1_romans, livres poche, nouvelles  \\\n",
       "id                                                       \n",
       "5540                                                 0   \n",
       "5528                                                 0   \n",
       "3434                                                 0   \n",
       "5621                                                 0   \n",
       "5267                                                 0   \n",
       "\n",
       "      sous_categorie_1_vinyles  sous_categorie_1_jupes, shorts femme  \\\n",
       "id                                                                     \n",
       "5540                         0                                     0   \n",
       "5528                         0                                     0   \n",
       "3434                         0                                     0   \n",
       "5621                         0                                     0   \n",
       "5267                         0                                     0   \n",
       "\n",
       "      sous_categorie_1_tricot, crochet  sous_categorie_1_littérature jeunesse  \\\n",
       "id                                                                              \n",
       "5540                                 0                                      0   \n",
       "5528                                 0                                      0   \n",
       "3434                                 0                                      0   \n",
       "5621                                 0                                      0   \n",
       "5267                                 0                                      0   \n",
       "\n",
       "      sous_categorie_1_objets déco et vaisselle  sous_categorie_1_DVDs  \\\n",
       "id                                                                       \n",
       "5540                                          0                      0   \n",
       "5528                                          0                      0   \n",
       "3434                                          0                      0   \n",
       "5621                                          0                      0   \n",
       "5267                                          0                      0   \n",
       "\n",
       "      sous_categorie_1_tops, t-shirts, débardeurs femme  \\\n",
       "id                                                        \n",
       "5540                                                  0   \n",
       "5528                                                  0   \n",
       "3434                                                  0   \n",
       "5621                                                  0   \n",
       "5267                                                  0   \n",
       "\n",
       "      sous_categorie_1_luminaires  \\\n",
       "id                                  \n",
       "5540                            0   \n",
       "5528                            0   \n",
       "3434                            0   \n",
       "5621                            0   \n",
       "5267                            0   \n",
       "\n",
       "      sous_categorie_1_services de vaisselle, vaisselle en lots  \\\n",
       "id                                                                \n",
       "5540                                                  0           \n",
       "5528                                                  0           \n",
       "3434                                                  0           \n",
       "5621                                                  0           \n",
       "5267                                                  0           \n",
       "\n",
       "      sous_categorie_1_linge de maison  sous_categorie_1_loisirs  \\\n",
       "id                                                                 \n",
       "5540                                 0                         0   \n",
       "5528                                 0                         0   \n",
       "3434                                 0                         0   \n",
       "5621                                 0                         0   \n",
       "5267                                 0                         0   \n",
       "\n",
       "      sous_categorie_1_gilets, pulls homme  \\\n",
       "id                                           \n",
       "5540                                     0   \n",
       "5528                                     0   \n",
       "3434                                     0   \n",
       "5621                                     0   \n",
       "5267                                     0   \n",
       "\n",
       "      sous_categorie_1_platines et radios  \\\n",
       "id                                          \n",
       "5540                                    0   \n",
       "5528                                    0   \n",
       "3434                                    0   \n",
       "5621                                    0   \n",
       "5267                                    0   \n",
       "\n",
       "      sous_categorie_1_ordinateurs de bureau  \\\n",
       "id                                             \n",
       "5540                                       0   \n",
       "5528                                       0   \n",
       "3434                                       0   \n",
       "5621                                       0   \n",
       "5267                                       0   \n",
       "\n",
       "      sous_categorie_1_vaisselle à l'unité  sous_categorie_1_librairie  \\\n",
       "id                                                                       \n",
       "5540                                     0                           0   \n",
       "5528                                     0                           0   \n",
       "3434                                     0                           0   \n",
       "5621                                     0                           0   \n",
       "5267                                     0                           0   \n",
       "\n",
       "      sous_categorie_1_accessoires homme  sous_categorie_1_Cartes postales  \\\n",
       "id                                                                           \n",
       "5540                                   0                                 0   \n",
       "5528                                   0                                 0   \n",
       "3434                                   0                                 0   \n",
       "5621                                   0                                 0   \n",
       "5267                                   0                                 0   \n",
       "\n",
       "      sous_categorie_1_chemises, polos homme  sous_categorie_1_véhicules  \\\n",
       "id                                                                         \n",
       "5540                                       0                           0   \n",
       "5528                                       0                           0   \n",
       "3434                                       0                           0   \n",
       "5621                                       0                           0   \n",
       "5267                                       0                           0   \n",
       "\n",
       "      sous_categorie_1_accessoires et maroquinerie  \\\n",
       "id                                                   \n",
       "5540                                             0   \n",
       "5528                                             0   \n",
       "3434                                             0   \n",
       "5621                                             0   \n",
       "5267                                             0   \n",
       "\n",
       "      sous_categorie_1_Romans de Gare  \\\n",
       "id                                      \n",
       "5540                                0   \n",
       "5528                                0   \n",
       "3434                                0   \n",
       "5621                                0   \n",
       "5267                                0   \n",
       "\n",
       "      sous_categorie_1_manteaux, blousons homme  \\\n",
       "id                                                \n",
       "5540                                          0   \n",
       "5528                                          0   \n",
       "3434                                          0   \n",
       "5621                                          0   \n",
       "5267                                          0   \n",
       "\n",
       "      sous_categorie_1_Maillots de bain  \\\n",
       "id                                        \n",
       "5540                                  0   \n",
       "5528                                  0   \n",
       "3434                                  0   \n",
       "5621                                  0   \n",
       "5267                                  0   \n",
       "\n",
       "      sous_categorie_1_rangements, étagères, escabeaux  \\\n",
       "id                                                       \n",
       "5540                                                 0   \n",
       "5528                                                 0   \n",
       "3434                                                 0   \n",
       "5621                                                 0   \n",
       "5267                                                 0   \n",
       "\n",
       "      sous_categorie_1_chaises, tabourets  sous_categorie_1_image et son  \\\n",
       "id                                                                         \n",
       "5540                                    0                              0   \n",
       "5528                                    0                              0   \n",
       "3434                                    0                              0   \n",
       "5621                                    0                              0   \n",
       "5267                                    0                              0   \n",
       "\n",
       "      sous_categorie_1_poupées  sous_categorie_1_BD et mangas  \\\n",
       "id                                                              \n",
       "5540                         0                              0   \n",
       "5528                         0                              0   \n",
       "3434                         0                              0   \n",
       "5621                         0                              0   \n",
       "5267                         0                              0   \n",
       "\n",
       "      sous_categorie_1_appareils photo et accessoires photo  \\\n",
       "id                                                            \n",
       "5540                                                  0       \n",
       "5528                                                  0       \n",
       "3434                                                  0       \n",
       "5621                                                  0       \n",
       "5267                                                  0       \n",
       "\n",
       "      sous_categorie_1_autres jouets  sous_categorie_1_chaussures  \\\n",
       "id                                                                  \n",
       "5540                               0                            0   \n",
       "5528                               0                            0   \n",
       "3434                               0                            0   \n",
       "5621                               0                            0   \n",
       "5267                               0                            0   \n",
       "\n",
       "      sous_categorie_1_périphériques et accessoires  \\\n",
       "id                                                    \n",
       "5540                                              0   \n",
       "5528                                              0   \n",
       "3434                                              0   \n",
       "5621                                              0   \n",
       "5267                                              0   \n",
       "\n",
       "      sous_categorie_1_Les héros des plus grands  \\\n",
       "id                                                 \n",
       "5540                                           0   \n",
       "5528                                           0   \n",
       "3434                                           0   \n",
       "5621                                           0   \n",
       "5267                                           0   \n",
       "\n",
       "      sous_categorie_1_culture - loisirs  sous_categorie_1_jeux et jouets  \\\n",
       "id                                                                          \n",
       "5540                                   0                                0   \n",
       "5528                                   0                                0   \n",
       "3434                                   0                                0   \n",
       "5621                                   0                                0   \n",
       "5267                                   0                                0   \n",
       "\n",
       "      sous_categorie_1_A carreaux !  sous_categorie_1_Vêtements été  \\\n",
       "id                                                                    \n",
       "5540                              0                               0   \n",
       "5528                              0                               0   \n",
       "3434                              0                               0   \n",
       "5621                              0                               0   \n",
       "5267                              0                               0   \n",
       "\n",
       "      sous_categorie_1_mode homme  sous_categorie_1_vestes, blazers homme  \\\n",
       "id                                                                          \n",
       "5540                            0                                       0   \n",
       "5528                            0                                       0   \n",
       "3434                            0                                       0   \n",
       "5621                            0                                       0   \n",
       "5267                            0                                       0   \n",
       "\n",
       "      sous_categorie_1_vie pratique, loisirs  \\\n",
       "id                                             \n",
       "5540                                       0   \n",
       "5528                                       0   \n",
       "3434                                       0   \n",
       "5621                                       0   \n",
       "5267                                       0   \n",
       "\n",
       "      sous_categorie_1_jouets anciens, jouets en bois  \\\n",
       "id                                                      \n",
       "5540                                                0   \n",
       "5528                                                0   \n",
       "3434                                                0   \n",
       "5621                                                0   \n",
       "5267                                                0   \n",
       "\n",
       "      sous_categorie_1_multimédia  sous_categorie_1_La Petite robe noire  \\\n",
       "id                                                                         \n",
       "5540                            0                                      0   \n",
       "5528                            0                                      0   \n",
       "3434                            0                                      0   \n",
       "5621                            0                                      0   \n",
       "5267                            0                                      0   \n",
       "\n",
       "      sous_categorie_1_Label Affaire ! (braderie à - de 10€)  \\\n",
       "id                                                             \n",
       "5540                                                  0        \n",
       "5528                                                  0        \n",
       "3434                                                  0        \n",
       "5621                                                  0        \n",
       "5267                                                  0        \n",
       "\n",
       "      sous_categorie_1_layette naissance - 18 mois  \\\n",
       "id                                                   \n",
       "5540                                             0   \n",
       "5528                                             0   \n",
       "3434                                             0   \n",
       "5621                                             0   \n",
       "5267                                             0   \n",
       "\n",
       "      sous_categorie_1_jeux vidéos et consoles  sous_categorie_1_smartphones  \\\n",
       "id                                                                             \n",
       "5540                                         0                             0   \n",
       "5528                                         0                             0   \n",
       "3434                                         0                             0   \n",
       "5621                                         0                             0   \n",
       "5267                                         0                             0   \n",
       "\n",
       "      sous_categorie_1_vélos  sous_categorie_1_vêtements garçon 6 - 12 ans  \\\n",
       "id                                                                           \n",
       "5540                       0                                             0   \n",
       "5528                       0                                             0   \n",
       "3434                       0                                             0   \n",
       "5621                       0                                             0   \n",
       "5267                       0                                             0   \n",
       "\n",
       "      sous_categorie_1_t-shirts, débardeurs homme  sous_categorie_1_sport  \\\n",
       "id                                                                          \n",
       "5540                                            0                       0   \n",
       "5528                                            0                       0   \n",
       "3434                                            0                       0   \n",
       "5621                                            0                       0   \n",
       "5267                                            0                       0   \n",
       "\n",
       "      sous_categorie_1_fournitures et papeterie  sous_categorie_1_Le Ski  \\\n",
       "id                                                                         \n",
       "5540                                          0                        0   \n",
       "5528                                          0                        0   \n",
       "3434                                          0                        0   \n",
       "5621                                          0                        0   \n",
       "5267                                          0                        0   \n",
       "\n",
       "      sous_categorie_1_ensembles, combinaisons, tailleurs femme  \\\n",
       "id                                                                \n",
       "5540                                                  0           \n",
       "5528                                                  0           \n",
       "3434                                                  0           \n",
       "5621                                                  0           \n",
       "5267                                                  0           \n",
       "\n",
       "      sous_categorie_1_instruments de musique  \\\n",
       "id                                              \n",
       "5540                                        0   \n",
       "5528                                        0   \n",
       "3434                                        0   \n",
       "5621                                        0   \n",
       "5267                                        0   \n",
       "\n",
       "      sous_categorie_1_livres d'images, livres enfants  \\\n",
       "id                                                       \n",
       "5540                                                 0   \n",
       "5528                                                 0   \n",
       "3434                                                 0   \n",
       "5621                                                 0   \n",
       "5267                                                 0   \n",
       "\n",
       "      sous_categorie_1_commodes, chevets, chiffonniers  \\\n",
       "id                                                       \n",
       "5540                                                 0   \n",
       "5528                                                 0   \n",
       "3434                                                 0   \n",
       "5621                                                 0   \n",
       "5267                                                 0   \n",
       "\n",
       "      sous_categorie_1_livres anciens  \\\n",
       "id                                      \n",
       "5540                                0   \n",
       "5528                                0   \n",
       "3434                                0   \n",
       "5621                                0   \n",
       "5267                                0   \n",
       "\n",
       "      sous_categorie_1_Horloges, Pendules, Réveils  \\\n",
       "id                                                   \n",
       "5540                                             0   \n",
       "5528                                             0   \n",
       "3434                                             0   \n",
       "5621                                             0   \n",
       "5267                                             0   \n",
       "\n",
       "      sous_categorie_1_machines à coudre, travailleuses, couturières  \\\n",
       "id                                                                     \n",
       "5540                                                  0                \n",
       "5528                                                  0                \n",
       "3434                                                  0                \n",
       "5621                                                  0                \n",
       "5267                                                  0                \n",
       "\n",
       "      sous_categorie_1_vêtements bébé, enfant, ado  \\\n",
       "id                                                   \n",
       "5540                                             0   \n",
       "5528                                             0   \n",
       "3434                                             0   \n",
       "5621                                             0   \n",
       "5267                                             0   \n",
       "\n",
       "      sous_categorie_1_Les héros des petits  \\\n",
       "id                                            \n",
       "5540                                      0   \n",
       "5528                                      0   \n",
       "3434                                      0   \n",
       "5621                                      0   \n",
       "5267                                      0   \n",
       "\n",
       "      sous_categorie_1_les coups de coeur des vendeurs  \\\n",
       "id                                                       \n",
       "5540                                                 0   \n",
       "5528                                                 0   \n",
       "3434                                                 0   \n",
       "5621                                                 0   \n",
       "5267                                                 0   \n",
       "\n",
       "      sous_categorie_1_vêtements ados  sous_categorie_1_Esprit Vintage  \\\n",
       "id                                                                       \n",
       "5540                                0                                0   \n",
       "5528                                0                                0   \n",
       "3434                                0                                0   \n",
       "5621                                0                                0   \n",
       "5267                                0                                0   \n",
       "\n",
       "      sous_categorie_1_CDs  sous_categorie_1_matériel et accessoires de sport  \\\n",
       "id                                                                              \n",
       "5540                     0                                                  0   \n",
       "5528                     0                                                  0   \n",
       "3434                     0                                                  0   \n",
       "5621                     0                                                  0   \n",
       "5267                     0                                                  0   \n",
       "\n",
       "      sous_categorie_1_Séries ado - Young Adult  \\\n",
       "id                                                \n",
       "5540                                          0   \n",
       "5528                                          0   \n",
       "3434                                          0   \n",
       "5621                                          0   \n",
       "5267                                          0   \n",
       "\n",
       "      sous_categorie_1_tissu, coupons, petite mercerie, accessoires couture  \\\n",
       "id                                                                            \n",
       "5540                                                  0                       \n",
       "5528                                                  0                       \n",
       "3434                                                  0                       \n",
       "5621                                                  0                       \n",
       "5267                                                  0                       \n",
       "\n",
       "      sous_categorie_1_littérature étrangère  \\\n",
       "id                                             \n",
       "5540                                       0   \n",
       "5528                                       0   \n",
       "3434                                       0   \n",
       "5621                                       0   \n",
       "5267                                       0   \n",
       "\n",
       "      sous_categorie_1_vêtements de sport femme  \\\n",
       "id                                                \n",
       "5540                                          0   \n",
       "5528                                          0   \n",
       "3434                                          0   \n",
       "5621                                          0   \n",
       "5267                                          0   \n",
       "\n",
       "      sous_categorie_1_platines et transistors  sous_categorie_1_écrans  \\\n",
       "id                                                                        \n",
       "5540                                         0                        0   \n",
       "5528                                         0                        0   \n",
       "3434                                         0                        0   \n",
       "5621                                         0                        0   \n",
       "5267                                         0                        0   \n",
       "\n",
       "      sous_categorie_1_fauteuils, poufs  \\\n",
       "id                                        \n",
       "5540                                  0   \n",
       "5528                                  0   \n",
       "3434                                  0   \n",
       "5621                                  0   \n",
       "5267                                  0   \n",
       "\n",
       "      sous_categorie_1_Cabinet de curiosités  \\\n",
       "id                                             \n",
       "5540                                       0   \n",
       "5528                                       0   \n",
       "3434                                       0   \n",
       "5621                                       0   \n",
       "5267                                       0   \n",
       "\n",
       "      sous_categorie_1_vêtements garçon 2 - 6 ans  \\\n",
       "id                                                  \n",
       "5540                                            0   \n",
       "5528                                            0   \n",
       "3434                                            0   \n",
       "5621                                            0   \n",
       "5267                                            0   \n",
       "\n",
       "      sous_categorie_1_Shorts, Bermudas, Maillots de bain Homme  \\\n",
       "id                                                                \n",
       "5540                                                  0           \n",
       "5528                                                  0           \n",
       "3434                                                  0           \n",
       "5621                                                  0           \n",
       "5267                                                  0           \n",
       "\n",
       "      sous_categorie_1_Le Cuir  sous_categorie_1_revues, magazines  \\\n",
       "id                                                                   \n",
       "5540                         0                                   0   \n",
       "5528                         0                                   0   \n",
       "3434                         0                                   0   \n",
       "5621                         0                                   0   \n",
       "5267                         0                                   0   \n",
       "\n",
       "      sous_categorie_1_playmobil, LEGO, Mécano  \\\n",
       "id                                               \n",
       "5540                                         0   \n",
       "5528                                         0   \n",
       "3434                                         0   \n",
       "5621                                         0   \n",
       "5267                                         0   \n",
       "\n",
       "      sous_categorie_1_Tous sur notre 31 !  sous_categorie_1_partitions  \\\n",
       "id                                                                        \n",
       "5540                                     0                            0   \n",
       "5528                                     0                            0   \n",
       "3434                                     0                            0   \n",
       "5621                                     0                            0   \n",
       "5267                                     0                            0   \n",
       "\n",
       "      sous_categorie_1_vêtements de sport homme  \\\n",
       "id                                                \n",
       "5540                                          0   \n",
       "5528                                          0   \n",
       "3434                                          0   \n",
       "5621                                          0   \n",
       "5267                                          0   \n",
       "\n",
       "      sous_categorie_1_accessoires enfant  sous_categorie_1_costumes homme  \\\n",
       "id                                                                           \n",
       "5540                                    0                                0   \n",
       "5528                                    0                                0   \n",
       "3434                                    0                                0   \n",
       "5621                                    0                                0   \n",
       "5267                                    0                                0   \n",
       "\n",
       "      sous_categorie_1_poussettes, couffins  \\\n",
       "id                                            \n",
       "5540                                      0   \n",
       "5528                                      0   \n",
       "3434                                      0   \n",
       "5621                                      0   \n",
       "5267                                      0   \n",
       "\n",
       "      sous_categorie_1_Vêtements Printemps  \\\n",
       "id                                           \n",
       "5540                                     0   \n",
       "5528                                     0   \n",
       "3434                                     0   \n",
       "5621                                     0   \n",
       "5267                                     0   \n",
       "\n",
       "      sous_categorie_1_Livres à moins de 5€  \\\n",
       "id                                            \n",
       "5540                                      0   \n",
       "5528                                      0   \n",
       "3434                                      0   \n",
       "5621                                      0   \n",
       "5267                                      0   \n",
       "\n",
       "      sous_categorie_1_Vêtements Vintage Femme  sous_categorie_1_Cérémonies  \\\n",
       "id                                                                            \n",
       "5540                                         0                            0   \n",
       "5528                                         0                            0   \n",
       "3434                                         0                            0   \n",
       "5621                                         0                            0   \n",
       "5267                                         0                            0   \n",
       "\n",
       "      sous_categorie_1_Label Fashion Week  sous_categorie_1_Déco Vintage  \\\n",
       "id                                                                         \n",
       "5540                                    0                              0   \n",
       "5528                                    0                              0   \n",
       "3434                                    0                              0   \n",
       "5621                                    0                              0   \n",
       "5267                                    0                              0   \n",
       "\n",
       "      sous_categorie_1_collections, cartes postales, timbres, monnaie, vieux papiers  \\\n",
       "id                                                                                     \n",
       "5540                                                  0                                \n",
       "5528                                                  0                                \n",
       "3434                                                  0                                \n",
       "5621                                                  0                                \n",
       "5267                                                  0                                \n",
       "\n",
       "      sous_categorie_1_rollers, skateboards, trotinettes  \\\n",
       "id                                                         \n",
       "5540                                                  0    \n",
       "5528                                                  0    \n",
       "3434                                                  0    \n",
       "5621                                                  0    \n",
       "5267                                                  0    \n",
       "\n",
       "      sous_categorie_1_objets régionaux  \\\n",
       "id                                        \n",
       "5540                                  0   \n",
       "5528                                  0   \n",
       "3434                                  0   \n",
       "5621                                  0   \n",
       "5267                                  0   \n",
       "\n",
       "      sous_categorie_1_vêtements fille 2 - 6 ans  \\\n",
       "id                                                 \n",
       "5540                                           0   \n",
       "5528                                           0   \n",
       "3434                                           0   \n",
       "5621                                           0   \n",
       "5267                                           0   \n",
       "\n",
       "      sous_categorie_1_poésie, théâtre  sous_categorie_1_Déco Romantique  \\\n",
       "id                                                                         \n",
       "5540                                 0                                 0   \n",
       "5528                                 0                                 0   \n",
       "3434                                 0                                 0   \n",
       "5621                                 0                                 0   \n",
       "5267                                 0                                 0   \n",
       "\n",
       "      sous_categorie_1_accessoires de puériculture  \\\n",
       "id                                                   \n",
       "5540                                             0   \n",
       "5528                                             0   \n",
       "3434                                             0   \n",
       "5621                                             0   \n",
       "5267                                             0   \n",
       "\n",
       "      sous_categorie_1_bricolage  sous_categorie_1_créations  \\\n",
       "id                                                             \n",
       "5540                           0                           0   \n",
       "5528                           0                           0   \n",
       "3434                           0                           0   \n",
       "5621                           0                           0   \n",
       "5267                           0                           0   \n",
       "\n",
       "      sous_categorie_1_livres scolaires  sous_categorie_1_Tenues de cérémonie  \\\n",
       "id                                                                              \n",
       "5540                                  0                                     0   \n",
       "5528                                  0                                     0   \n",
       "3434                                  0                                     0   \n",
       "5621                                  0                                     0   \n",
       "5267                                  0                                     0   \n",
       "\n",
       "      sous_categorie_1_canapés, banquettes, bancs  \\\n",
       "id                                                  \n",
       "5540                                            0   \n",
       "5528                                            0   \n",
       "3434                                            0   \n",
       "5621                                            0   \n",
       "5267                                            0   \n",
       "\n",
       "      sous_categorie_1_vêtements de sport enfant  \\\n",
       "id                                                 \n",
       "5540                                           0   \n",
       "5528                                           0   \n",
       "3434                                           0   \n",
       "5621                                           0   \n",
       "5267                                           0   \n",
       "\n",
       "      sous_categorie_1_buffets, enfilades  \\\n",
       "id                                          \n",
       "5540                                    0   \n",
       "5528                                    0   \n",
       "3434                                    0   \n",
       "5621                                    0   \n",
       "5267                                    0   \n",
       "\n",
       "      sous_categorie_1_armoires, vitrines, bibliothèques  \\\n",
       "id                                                         \n",
       "5540                                                  0    \n",
       "5528                                                  0    \n",
       "3434                                                  0    \n",
       "5621                                                  0    \n",
       "5267                                                  0    \n",
       "\n",
       "      sous_categorie_1_jeux d'éveil  sous_categorie_1_On continue, l'abbé !  \\\n",
       "id                                                                            \n",
       "5540                              0                                       0   \n",
       "5528                              0                                       0   \n",
       "3434                              0                                       0   \n",
       "5621                              0                                       0   \n",
       "5267                              0                                       0   \n",
       "\n",
       "      sous_categorie_1_Déco Couleurs Naturelles et Doré  \\\n",
       "id                                                        \n",
       "5540                                                  0   \n",
       "5528                                                  0   \n",
       "3434                                                  0   \n",
       "5621                                                  0   \n",
       "5267                                                  0   \n",
       "\n",
       "      sous_categorie_1_petit mobilier  \\\n",
       "id                                      \n",
       "5540                                0   \n",
       "5528                                0   \n",
       "3434                                0   \n",
       "5621                                0   \n",
       "5267                                0   \n",
       "\n",
       "      sous_categorie_1_loisirs créatifs, couture, mercerie, déguisements  \\\n",
       "id                                                                         \n",
       "5540                                                  0                    \n",
       "5528                                                  0                    \n",
       "3434                                                  0                    \n",
       "5621                                                  0                    \n",
       "5267                                                  0                    \n",
       "\n",
       "      sous_categorie_1_culture, société, voyages  \\\n",
       "id                                                 \n",
       "5540                                           0   \n",
       "5528                                           0   \n",
       "3434                                           0   \n",
       "5621                                           0   \n",
       "5267                                           0   \n",
       "\n",
       "      sous_categorie_1_chaussures enfant  sous_categorie_1_tapis  \\\n",
       "id                                                                 \n",
       "5540                                   0                       0   \n",
       "5528                                   0                       0   \n",
       "3434                                   0                       0   \n",
       "5621                                   0                       0   \n",
       "5267                                   0                       0   \n",
       "\n",
       "      sous_categorie_1_Journée de la femme  sous_categorie_1_déguisements  \\\n",
       "id                                                                          \n",
       "5540                                     0                              0   \n",
       "5528                                     0                              0   \n",
       "3434                                     0                              0   \n",
       "5621                                     0                              0   \n",
       "5267                                     0                              0   \n",
       "\n",
       "      sous_categorie_1_ordinateurs portables  sous_categorie_1_Noël  \\\n",
       "id                                                                    \n",
       "5540                                       0                      0   \n",
       "5528                                       0                      0   \n",
       "3434                                       0                      0   \n",
       "5621                                       0                      0   \n",
       "5267                                       0                      0   \n",
       "\n",
       "      sous_categorie_1_mobiles  sous_categorie_1_gros mobilier  \\\n",
       "id                                                               \n",
       "5540                         0                               0   \n",
       "5528                         0                               0   \n",
       "3434                         0                               0   \n",
       "5621                         0                               0   \n",
       "5267                         0                               0   \n",
       "\n",
       "      sous_categorie_1_dentelles  sous_categorie_1_Denim pour tous !  \\\n",
       "id                                                                     \n",
       "5540                           0                                   0   \n",
       "5528                           0                                   0   \n",
       "3434                           0                                   0   \n",
       "5621                           0                                   0   \n",
       "5267                           0                                   0   \n",
       "\n",
       "      sous_categorie_1_Fête de la musique  sous_categorie_1_tables et bureaux  \\\n",
       "id                                                                              \n",
       "5540                                    0                                   0   \n",
       "5528                                    0                                   0   \n",
       "3434                                    0                                   0   \n",
       "5621                                    0                                   0   \n",
       "5267                                    0                                   0   \n",
       "\n",
       "      sous_categorie_1_meubles de métier  sous_categorie_1_imprimantes  \\\n",
       "id                                                                       \n",
       "5540                                   0                             0   \n",
       "5528                                   0                             0   \n",
       "3434                                   0                             0   \n",
       "5621                                   0                             0   \n",
       "5267                                   0                             0   \n",
       "\n",
       "      sous_categorie_1_Déco Kitsch  sous_categorie_1_Métiers d'hier  \\\n",
       "id                                                                    \n",
       "5540                             0                                0   \n",
       "5528                             0                                0   \n",
       "3434                             0                                0   \n",
       "5621                             0                                0   \n",
       "5267                             0                                0   \n",
       "\n",
       "      sous_categorie_1_Vélorution !  sous_categorie_1_tablettes  \\\n",
       "id                                                                \n",
       "5540                              0                           0   \n",
       "5528                              0                           0   \n",
       "3434                              0                           0   \n",
       "5621                              0                           0   \n",
       "5267                              0                           0   \n",
       "\n",
       "      sous_categorie_1_Shabby Chic  sous_categorie_1_Enfin le printemps !  \\\n",
       "id                                                                          \n",
       "5540                             0                                      0   \n",
       "5528                             0                                      0   \n",
       "3434                             0                                      0   \n",
       "5621                             0                                      0   \n",
       "5267                             0                                      0   \n",
       "\n",
       "      nom_magasin_Emmaüs 88 Neufchateau  \\\n",
       "id                                        \n",
       "5540                                  0   \n",
       "5528                                  1   \n",
       "3434                                  0   \n",
       "5621                                  0   \n",
       "5267                                  0   \n",
       "\n",
       "      nom_magasin_Frip'Insertion Marseille Libération  \\\n",
       "id                                                      \n",
       "5540                                                0   \n",
       "5528                                                0   \n",
       "3434                                                1   \n",
       "5621                                                0   \n",
       "5267                                                0   \n",
       "\n",
       "      nom_magasin_Booki - la Librairie Solidaire de Retrilog  \\\n",
       "id                                                             \n",
       "5540                                                  0        \n",
       "5528                                                  0        \n",
       "3434                                                  0        \n",
       "5621                                                  1        \n",
       "5267                                                  0        \n",
       "\n",
       "      nom_magasin_Emmaüs Lyon  nom_magasin_Label Emmaüs Chambéry  \\\n",
       "id                                                                 \n",
       "5540                        0                                  0   \n",
       "5528                        0                                  0   \n",
       "3434                        0                                  0   \n",
       "5621                        0                                  0   \n",
       "5267                        1                                  0   \n",
       "\n",
       "      nom_magasin_Le Léopard  nom_magasin_Labelemmaus Vendée  \\\n",
       "id                                                             \n",
       "5540                       0                               0   \n",
       "5528                       0                               0   \n",
       "3434                       0                               0   \n",
       "5621                       0                               0   \n",
       "5267                       0                               0   \n",
       "\n",
       "      nom_magasin_Emmaüs Avenir Neuilly sur Marne  \\\n",
       "id                                                  \n",
       "5540                                            0   \n",
       "5528                                            0   \n",
       "3434                                            0   \n",
       "5621                                            0   \n",
       "5267                                            0   \n",
       "\n",
       "      nom_magasin_Emmaüs Sacré Dressing !  \\\n",
       "id                                          \n",
       "5540                                    0   \n",
       "5528                                    0   \n",
       "3434                                    0   \n",
       "5621                                    0   \n",
       "5267                                    0   \n",
       "\n",
       "      nom_magasin_ADBook - la Librairie Solidaire des Ateliers du Bocage  \\\n",
       "id                                                                         \n",
       "5540                                                  0                    \n",
       "5528                                                  0                    \n",
       "3434                                                  0                    \n",
       "5621                                                  0                    \n",
       "5267                                                  0                    \n",
       "\n",
       "      nom_magasin_Label Emmaüs de Grenoble  \\\n",
       "id                                           \n",
       "5540                                     0   \n",
       "5528                                     0   \n",
       "3434                                     0   \n",
       "5621                                     0   \n",
       "5267                                     0   \n",
       "\n",
       "      nom_magasin_La Boutique Emmaüs d’Auray  \\\n",
       "id                                             \n",
       "5540                                       0   \n",
       "5528                                       0   \n",
       "3434                                       0   \n",
       "5621                                       0   \n",
       "5267                                       0   \n",
       "\n",
       "      nom_magasin_Communauté Emmaüs Thouars (magasin Parthenay)  \\\n",
       "id                                                                \n",
       "5540                                                  0           \n",
       "5528                                                  0           \n",
       "3434                                                  0           \n",
       "5621                                                  0           \n",
       "5267                                                  0           \n",
       "\n",
       "      nom_magasin_Frip'Attitude Emmaüs Vêtement  \\\n",
       "id                                                \n",
       "5540                                          0   \n",
       "5528                                          0   \n",
       "3434                                          0   \n",
       "5621                                          0   \n",
       "5267                                          0   \n",
       "\n",
       "      nom_magasin_Emmaüs Saintes Saint Romain  \\\n",
       "id                                              \n",
       "5540                                        0   \n",
       "5528                                        0   \n",
       "3434                                        0   \n",
       "5621                                        0   \n",
       "5267                                        0   \n",
       "\n",
       "      nom_magasin_La Boutique Emmaüs de Lorient Plénéno  \\\n",
       "id                                                        \n",
       "5540                                                  0   \n",
       "5528                                                  0   \n",
       "3434                                                  0   \n",
       "5621                                                  0   \n",
       "5267                                                  0   \n",
       "\n",
       "      nom_magasin_Label Emmaus Angers  nom_magasin_Emmaüs Liberté Ivry  \\\n",
       "id                                                                       \n",
       "5540                                0                                0   \n",
       "5528                                0                                0   \n",
       "3434                                0                                0   \n",
       "5621                                0                                0   \n",
       "5267                                0                                0   \n",
       "\n",
       "      nom_magasin_Ding Fring – En mode solidaire  \\\n",
       "id                                                 \n",
       "5540                                           0   \n",
       "5528                                           0   \n",
       "3434                                           0   \n",
       "5621                                           0   \n",
       "5267                                           0   \n",
       "\n",
       "      nom_magasin_Emmaüs Vannes - la Boutique en ligne  \\\n",
       "id                                                       \n",
       "5540                                                 0   \n",
       "5528                                                 0   \n",
       "3434                                                 0   \n",
       "5621                                                 0   \n",
       "5267                                                 0   \n",
       "\n",
       "      nom_magasin_Comité d'amis Emmaüs Roanne Mably  \\\n",
       "id                                                    \n",
       "5540                                              0   \n",
       "5528                                              0   \n",
       "3434                                              0   \n",
       "5621                                              0   \n",
       "5267                                              0   \n",
       "\n",
       "      nom_magasin_Communauté Emmaüs Soissons  \\\n",
       "id                                             \n",
       "5540                                       0   \n",
       "5528                                       0   \n",
       "3434                                       0   \n",
       "5621                                       0   \n",
       "5267                                       0   \n",
       "\n",
       "      nom_magasin_Emmaüs Indre Le Blanc  nom_magasin_Emmaüs Défi 104  \\\n",
       "id                                                                     \n",
       "5540                                  0                            0   \n",
       "5528                                  0                            0   \n",
       "3434                                  0                            0   \n",
       "5621                                  0                            0   \n",
       "5267                                  0                            0   \n",
       "\n",
       "      nom_magasin_Comité d'amis Emmaüs Millau  \\\n",
       "id                                              \n",
       "5540                                        0   \n",
       "5528                                        0   \n",
       "3434                                        0   \n",
       "5621                                        0   \n",
       "5267                                        0   \n",
       "\n",
       "      nom_magasin_Emmaüs St Etienne - Firminy  \\\n",
       "id                                              \n",
       "5540                                        0   \n",
       "5528                                        0   \n",
       "3434                                        0   \n",
       "5621                                        0   \n",
       "5267                                        0   \n",
       "\n",
       "      nom_magasin_Comité d'amis Emmaüs Pont Audemer  \\\n",
       "id                                                    \n",
       "5540                                              0   \n",
       "5528                                              0   \n",
       "3434                                              0   \n",
       "5621                                              0   \n",
       "5267                                              0   \n",
       "\n",
       "      nom_magasin_La Boutique Emmaüs Pontivy  nom_magasin_Emmaus Chenôve  \\\n",
       "id                                                                         \n",
       "5540                                       0                           0   \n",
       "5528                                       0                           0   \n",
       "3434                                       0                           0   \n",
       "5621                                       0                           0   \n",
       "5267                                       0                           0   \n",
       "\n",
       "      nom_magasin_La Bootique des Ateliers du Bocage  \\\n",
       "id                                                     \n",
       "5540                                               0   \n",
       "5528                                               0   \n",
       "3434                                               0   \n",
       "5621                                               0   \n",
       "5267                                               0   \n",
       "\n",
       "      nom_magasin_Emmaüs Alternatives Sélection  \\\n",
       "id                                                \n",
       "5540                                          0   \n",
       "5528                                          0   \n",
       "3434                                          0   \n",
       "5621                                          0   \n",
       "5267                                          0   \n",
       "\n",
       "      nom_magasin_Le coin de l'e-chineur  \\\n",
       "id                                         \n",
       "5540                                   0   \n",
       "5528                                   0   \n",
       "3434                                   0   \n",
       "5621                                   0   \n",
       "5267                                   0   \n",
       "\n",
       "      nom_magasin_Comité d'amis Emmaüs Beauvais  nom_magasin_L'Abri 88  \\\n",
       "id                                                                       \n",
       "5540                                          0                      0   \n",
       "5528                                          0                      0   \n",
       "3434                                          0                      0   \n",
       "5621                                          0                      0   \n",
       "5267                                          0                      0   \n",
       "\n",
       "      nom_magasin_Tri Rhône-Alpes - la Boutique en ligne  \\\n",
       "id                                                         \n",
       "5540                                                  0    \n",
       "5528                                                  0    \n",
       "3434                                                  0    \n",
       "5621                                                  0    \n",
       "5267                                                  0    \n",
       "\n",
       "      nom_magasin_Communauté Emmaüs Angoulême  \\\n",
       "id                                              \n",
       "5540                                        0   \n",
       "5528                                        0   \n",
       "3434                                        0   \n",
       "5621                                        0   \n",
       "5267                                        0   \n",
       "\n",
       "      nom_magasin_Ding Fring - En page solidaire  \\\n",
       "id                                                 \n",
       "5540                                           0   \n",
       "5528                                           0   \n",
       "3434                                           0   \n",
       "5621                                           0   \n",
       "5267                                           0   \n",
       "\n",
       "      nom_magasin_Emmaüs Mobilier Pro  \\\n",
       "id                                      \n",
       "5540                                0   \n",
       "5528                                0   \n",
       "3434                                0   \n",
       "5621                                0   \n",
       "5267                                0   \n",
       "\n",
       "      nom_magasin_Comité d'amis Emmaüs Ruffec  nom_magasin_Atelier Emmaüs  \\\n",
       "id                                                                          \n",
       "5540                                        0                           0   \n",
       "5528                                        0                           0   \n",
       "3434                                        0                           0   \n",
       "5621                                        0                           0   \n",
       "5267                                        0                           0   \n",
       "\n",
       "      nom_magasin_La Boutique militante : Article 13  \\\n",
       "id                                                     \n",
       "5540                                               0   \n",
       "5528                                               0   \n",
       "3434                                               0   \n",
       "5621                                               0   \n",
       "5267                                               0   \n",
       "\n",
       "      nom_magasin_Librairie Colibrio  nom_magasin_Communauté Emmaüs Thouars  \\\n",
       "id                                                                            \n",
       "5540                               0                                      0   \n",
       "5528                               0                                      0   \n",
       "3434                               0                                      0   \n",
       "5621                               0                                      0   \n",
       "5267                               0                                      0   \n",
       "\n",
       "      nom_magasin_Boutique des amis d'Emmaüs Apt  \n",
       "id                                                \n",
       "5540                                           0  \n",
       "5528                                           0  \n",
       "3434                                           0  \n",
       "5621                                           0  \n",
       "5267                                           0  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of the Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For several algorithm (for example, neural network), it is required to normalize the input data. For example, for neural network, the goal is to avoid vanishing gradient. But this technic is also useful for dimensionality reduction, for example with a PCA in order to have the same of variance for all the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:20:15.360552Z",
     "start_time": "2018-06-07T00:20:15.339177Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = ['nb_images',\t'longueur_image',\t'largeur_image',\t'etat',\n",
    "                      'vintage',\t'poids',\t'prix',\t'description_sentiment',\t'description_subjectivity',\n",
    "                      'description_car', 'description_wor', 'nom_car', 'nom_wor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: etat is categorical, but we consider it as numerical because it is an ordered realation between categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:20:24.443534Z",
     "start_time": "2018-06-07T00:20:24.380774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_images\n",
      "longueur_image\n",
      "largeur_image\n",
      "etat\n",
      "vintage\n",
      "poids\n",
      "prix\n",
      "description_sentiment\n",
      "description_subjectivity\n",
      "description_car\n",
      "description_wor\n",
      "nom_car\n",
      "nom_wor\n"
     ]
    }
   ],
   "source": [
    "for c in numerical_features:\n",
    "    print(c)\n",
    "    mean_x_train = x_train[c].mean()\n",
    "    std_x_train = x_train[c].std()\n",
    "    x_train[c] = (x_train[c] - mean_x_train)/std_x_train\n",
    "    x_val[c] = (x_val[c] - mean_x_train)/std_x_train\n",
    "\n",
    "    mean_X_train = X_train[c].mean()\n",
    "    std_X_train = X_train[c].std()\n",
    "    X_train[c] = (X_train[c] - mean_X_train)/std_X_train\n",
    "    X_test[c] = (X_test[c] - mean_x_train)/std_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:20:31.707620Z",
     "start_time": "2018-06-07T00:20:31.694957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5742448100138561e-16"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.longueur_image.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are done with the data. Let's play with algorithms ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T22:13:14.636126Z",
     "start_time": "2018-06-05T22:12:06.605Z"
    }
   },
   "source": [
    "## Dimensionality Reduction: Feature Selection \n",
    "\n",
    "See:http://scikit-learn.org/stable/modules/feature_selection.html <br><br>\n",
    "Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested.<br>\n",
    "<br>\n",
    "Having irrelevant features in your data can decrease the accuracy of many models, especially linear algorithms like linear and logistic regression.<br>\n",
    "<br>\n",
    "Three benefits of performing feature selection before modeling your data are:<br>\n",
    "<br>\n",
    "- <b>Reduces Overfitting:</b> Less redundant data means less opportunity to make decisions based on noise.<br>\n",
    "    <br>\n",
    "- <b>Improves Accuracy:</b> Less misleading data means modeling accuracy improves.<br>\n",
    "    <br>\n",
    "- <b>Reduces Training Time:</b> Less data means that algorithms train faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T23:51:30.277627Z",
     "start_time": "2018-06-06T23:51:30.272263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 238 features in total.\n"
     ]
    }
   ],
   "source": [
    "print('We have ' + str(X_train.shape[1]) + ' features in total.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reduce this number: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T23:58:21.834690Z",
     "start_time": "2018-06-06T23:58:21.828716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want to test our models with [10, 20, 59, 119, 214] features extracted from the 238 previous features\n"
     ]
    }
   ],
   "source": [
    "list_N = [10, 20, int(X_train.shape[1]/4),\n",
    "          int(X_train.shape[1]/2), int(X_train.shape[1]*0.9)]\n",
    "\n",
    "print('We want to test our models with ' + str(list_N) +\n",
    "      ' features extracted from the ' + str(np.shape(X_train)[1]) + ' previous features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T23:58:26.347638Z",
     "start_time": "2018-06-06T23:58:26.344124Z"
    }
   },
   "outputs": [],
   "source": [
    "def sel_pca(N):\n",
    "    \"\"\"\n",
    "    This function takes as input the number of kept features and return the PCA matrix. \n",
    "    \"\"\"\n",
    "    return ('PCA_{}'.format(N), PCA(n_components=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T23:58:26.356917Z",
     "start_time": "2018-06-06T23:58:26.349645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PCA_10',\n",
       "  PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)),\n",
       " ('PCA_20',\n",
       "  PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)),\n",
       " ('PCA_59',\n",
       "  PCA(copy=True, iterated_power='auto', n_components=59, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)),\n",
       " ('PCA_119',\n",
       "  PCA(copy=True, iterated_power='auto', n_components=119, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)),\n",
       " ('PCA_214',\n",
       "  PCA(copy=True, iterated_power='auto', n_components=214, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False))]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_PCA = list()\n",
    "for n in list_N:\n",
    "    list_PCA.append(sel_pca(n))\n",
    "list_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T23:58:34.277236Z",
     "start_time": "2018-06-06T23:58:34.273308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "print(set(y_train.delai_vente))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 3-label classification problem. We can use multi-class classifier so. Let's look at 4 classifiers:\n",
    "- NaiveBayes \n",
    "- RandomForest\n",
    "- LogisticRegression\n",
    "- SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T23:58:38.384726Z",
     "start_time": "2018-06-06T23:58:38.379488Z"
    }
   },
   "outputs": [],
   "source": [
    "list_classifier = [('LR', LogisticRegression()), ('SVM',  SVC(\n",
    "    probability=True)), ('RFC', RandomForestClassifier()), ('NB', GaussianNB())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline & Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set different pipelines with the values of N and the the classifiers and try them. Then, we'll be able to chose the best pipeline among them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T23:58:42.321838Z",
     "start_time": "2018-06-06T23:58:42.319203Z"
    }
   },
   "outputs": [],
   "source": [
    "list_result = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T23:58:42.334840Z",
     "start_time": "2018-06-06T23:58:42.324309Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluation(pca_N, classifier):\n",
    "    \"\"\"\n",
    "    This function takes as input a PCA(N=n) and a classifier. \n",
    "    And return a tuple containing both the log loss and accuracy of the pipeline composed of these elements. \n",
    "    \"\"\"\n",
    "    ppl = Pipeline([pca_N,\n",
    "                    classifier])\n",
    "    ppl.fit(x_train, np.ravel(y_train))\n",
    "    y_pred = ppl.predict(x_val)\n",
    "    y_prob_output = ppl.predict_proba(x_val)\n",
    "\n",
    "    ll = log_loss(y_pred=y_prob_output, y_true=y_val)\n",
    "    ac = accuracy_score(y_pred, y_val)\n",
    "    return (pca_N[0], classifier[0], ll, ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:02:00.599989Z",
     "start_time": "2018-06-06T23:58:46.679460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:13<00:00, 38.78s/it]\n"
     ]
    }
   ],
   "source": [
    "for pca_N in tqdm(list_PCA):\n",
    "    for classifier in list_classifier:\n",
    "        e = evaluation(pca_N, classifier)\n",
    "        list_result.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:02:08.774756Z",
     "start_time": "2018-06-07T00:02:08.767470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PCA_10', 'LR', 1.0801633965245714, 0.4099099099099099),\n",
       " ('PCA_10', 'SVM', 1.0364992200847885, 0.4624624624624625),\n",
       " ('PCA_10', 'RFC', 2.2670705356919907, 0.4283033033033033),\n",
       " ('PCA_10', 'NB', 1.3583787533904845, 0.4005255255255255),\n",
       " ('PCA_20', 'LR', 1.0745242356594902, 0.4253003003003003),\n",
       " ('PCA_20', 'SVM', 1.0325699011072258, 0.4692192192192192),\n",
       " ('PCA_20', 'RFC', 1.9546127825764048, 0.4391891891891892),\n",
       " ('PCA_20', 'NB', 1.3661080214644725, 0.41291291291291293),\n",
       " ('PCA_59', 'LR', 1.0384235553600787, 0.4553303303303303),\n",
       " ('PCA_59', 'SVM', 1.0299949622305167, 0.4583333333333333),\n",
       " ('PCA_59', 'RFC', 2.1095422657921685, 0.43205705705705705),\n",
       " ('PCA_59', 'NB', 2.1124706496168857, 0.4159159159159159),\n",
       " ('PCA_119', 'LR', 1.0203378649428476, 0.46959459459459457),\n",
       " ('PCA_119', 'SVM', 1.037288887417129, 0.45157657657657657),\n",
       " ('PCA_119', 'RFC', 2.2800652505827417, 0.44594594594594594),\n",
       " ('PCA_119', 'NB', 4.619885684500732, 0.42004504504504503),\n",
       " ('PCA_214', 'LR', 1.0156298590242006, 0.4752252252252252),\n",
       " ('PCA_214', 'SVM', 1.05104409413012, 0.4380630630630631),\n",
       " ('PCA_214', 'RFC', 2.1601153527806956, 0.44406906906906907),\n",
       " ('PCA_214', 'NB', 9.333087222047952, 0.39677177177177175)]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:02:12.946100Z",
     "start_time": "2018-06-07T00:02:12.943200Z"
    }
   },
   "outputs": [],
   "source": [
    "list_result.sort(key=lambda tup: tup[2], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:02:17.339790Z",
     "start_time": "2018-06-07T00:02:17.332783Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PCA_214', 'LR', 1.0156298590242006, 0.4752252252252252),\n",
       " ('PCA_119', 'LR', 1.0203378649428476, 0.46959459459459457),\n",
       " ('PCA_59', 'SVM', 1.0299949622305167, 0.4583333333333333),\n",
       " ('PCA_20', 'SVM', 1.0325699011072258, 0.4692192192192192),\n",
       " ('PCA_10', 'SVM', 1.0364992200847885, 0.4624624624624625),\n",
       " ('PCA_119', 'SVM', 1.037288887417129, 0.45157657657657657),\n",
       " ('PCA_59', 'LR', 1.0384235553600787, 0.4553303303303303),\n",
       " ('PCA_214', 'SVM', 1.05104409413012, 0.4380630630630631),\n",
       " ('PCA_20', 'LR', 1.0745242356594902, 0.4253003003003003),\n",
       " ('PCA_10', 'LR', 1.0801633965245714, 0.4099099099099099),\n",
       " ('PCA_10', 'NB', 1.3583787533904845, 0.4005255255255255),\n",
       " ('PCA_20', 'NB', 1.3661080214644725, 0.41291291291291293),\n",
       " ('PCA_20', 'RFC', 1.9546127825764048, 0.4391891891891892),\n",
       " ('PCA_59', 'RFC', 2.1095422657921685, 0.43205705705705705),\n",
       " ('PCA_59', 'NB', 2.1124706496168857, 0.4159159159159159),\n",
       " ('PCA_214', 'RFC', 2.1601153527806956, 0.44406906906906907),\n",
       " ('PCA_10', 'RFC', 2.2670705356919907, 0.4283033033033033),\n",
       " ('PCA_119', 'RFC', 2.2800652505827417, 0.44594594594594594),\n",
       " ('PCA_119', 'NB', 4.619885684500732, 0.42004504504504503),\n",
       " ('PCA_214', 'NB', 9.333087222047952, 0.39677177177177175)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's like the best classifier is the logistic regression with the more number of features. Let's try the logistic regression with no PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:53:44.722810Z",
     "start_time": "2018-06-07T02:53:44.536260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0152122592972987\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.49      0.45       804\n",
      "          1       0.29      0.48      0.37       540\n",
      "          2       0.72      0.47      0.57      1320\n",
      "\n",
      "avg / total       0.54      0.48      0.49      2664\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[393, 256, 155],\n",
       "       [195, 261,  84],\n",
       "       [337, 369, 614]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(x_train, np.ravel(y_train))\n",
    "y_pred = clf.predict(x_val)\n",
    "y_prob_output = clf.predict_proba(x_val)\n",
    "print(log_loss(y_pred=y_prob_output, y_true=y_val))\n",
    "print(classification_report(y_pred, y_val))\n",
    "confusion_matrix(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best result reached so far. Let's use it for submission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: \n",
    "- label0: Between 0 and 10 days\n",
    "- label1: Between 10 and 60 days\n",
    "- label2: 0ver 60 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix we can remark the label 2 is really well predicted ( precision 72%). And there is a lot a misclassification between label 0 and 1. We would think of improving the model using first this classifier to identify the id which belongs to label 2. And then, we'll be able to perform a new pipeline on the remaining ids in order to get the best classifier for those ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our LogReg with X_test in order to submit it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:37:03.622443Z",
     "start_time": "2018-06-07T00:37:03.201413Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, np.ravel(Y_train))\n",
    "y_pred = clf.predict(X_test)\n",
    "Y_prob_output = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:37:28.524340Z",
     "start_time": "2018-06-07T00:37:28.488236Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_prob_output = clf.predict_proba(X_test)\n",
    "df_submission = pd.DataFrame(Y_prob_output, index=X_test.index)\n",
    "df_submission.to_csv(\"my_prediction3.csv\",\n",
    "                     index_label=\"id\", header=['0', '1', '2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T02:57:14.465795Z",
     "start_time": "2018-06-06T02:56:07.711Z"
    }
   },
   "source": [
    "I scored <b>1.01409</b> on the platform with this model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T01:57:54.802404Z",
     "start_time": "2018-06-06T01:57:54.776230Z"
    }
   },
   "source": [
    "# A deep learning approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of data for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lines are here for converting DataFrame to matrices. Also, for the deep learning, the labels correspond to n different neurons to fire. So, the y vectors should be transformed with one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T01:01:25.916535Z",
     "start_time": "2018-06-07T01:01:25.874986Z"
    }
   },
   "outputs": [],
   "source": [
    "# X transformation\n",
    "X_train_k = X_train.values\n",
    "x_train_k = x_train.values\n",
    "x_val_k = x_val.values\n",
    "X_test_k = X_test.values\n",
    "\n",
    "# y transformation\n",
    "num_classes = 3\n",
    "\n",
    "Y_train_k = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_train_k = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val_k = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T01:01:30.289370Z",
     "start_time": "2018-06-07T01:01:30.283184Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8880, 237)\n",
      "(6216, 229)\n",
      "(2664, 229)\n",
      "(2960, 237)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_k.shape)\n",
    "print(x_train_k.shape)\n",
    "print(x_val_k.shape)\n",
    "print(X_test_k.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: The difference in shape is due to some dummies which are not in x_train but are in x_val."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T02:12:16.128951Z",
     "start_time": "2018-06-06T02:12:16.126308Z"
    }
   },
   "source": [
    "## Parameters & Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:26:51.796477Z",
     "start_time": "2018-06-07T02:26:51.793340Z"
    }
   },
   "outputs": [],
   "source": [
    "num_features = X_train_k.shape[1]\n",
    "num_features_small_x = x_train_k.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:26:56.986622Z",
     "start_time": "2018-06-07T02:26:56.952713Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2 fully connected layers\n",
    "\n",
    "# input layer\n",
    "input_layer_x = num_features_small_x\n",
    "input_layer = num_features\n",
    "\n",
    "# hidden layer\n",
    "layer1 = 128\n",
    "layer2 = 32\n",
    "layer3 = 32\n",
    "#layer4 = 16\n",
    "#layer5 = 8\n",
    "\n",
    "# drop proba for the dropout (in Keras we specify the droping probability/ in Tensorflow it's the keeping probability)\n",
    "# the dropout limits the overfitting\n",
    "drop_prob = 0.5\n",
    "\n",
    "\n",
    "# the drawback of the drop_out is the increasing in required epochs to train the model\n",
    "\n",
    "# loss\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "learning = 1e-4\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 200\n",
    "\n",
    "opt = Nadam(lr=learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:17:13.437269Z",
     "start_time": "2018-06-07T02:17:13.322710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 128)               29440     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 34,723\n",
      "Trainable params: 34,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "# fully connected layers\n",
    "# layer1\n",
    "model.add(Dense(layer1, activation='relu', input_dim=input_layer_x))\n",
    "# input_dim is the number of inputs\n",
    "\n",
    "# dropout\n",
    "model.add(Dropout(drop_prob))\n",
    "\n",
    "# layer2\n",
    "model.add(Dense(layer2, activation='relu'))\n",
    "\n",
    "# dropout\n",
    "model.add(Dropout(drop_prob))\n",
    "\n",
    "# layer3\n",
    "model.add(Dense(layer3, activation='relu'))\n",
    "\n",
    "# dropout\n",
    "model.add(Dropout(drop_prob))\n",
    "\n",
    "# layer4\n",
    "#model.add(Dense(layer4, activation='relu'))\n",
    "\n",
    "# dropout\n",
    "# model.add(Dropout(drop_prob))\n",
    "\n",
    "# layer5\n",
    "#model.add(Dense(layer5, activation='relu'))\n",
    "# dropout\n",
    "# model.add(Dropout(drop_prob))\n",
    "\n",
    "# softmax layer\n",
    "# the softmax layer produces probability\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# Visualizing the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:21:32.315227Z",
     "start_time": "2018-06-07T02:17:17.506602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6216 samples, validate on 2664 samples\n",
      "Epoch 1/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 1.1486 - acc: 0.3320- ETA: 2s - loss: 1.1553\n",
      "Epoch 00001: val_loss improved from inf to 1.09646, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 3s 535us/step - loss: 1.1484 - acc: 0.3319 - val_loss: 1.0965 - val_acc: 0.3679\n",
      "Epoch 2/200\n",
      "6048/6216 [============================>.] - ETA: 0s - loss: 1.1312 - acc: 0.3388\n",
      "Epoch 00002: val_loss improved from 1.09646 to 1.09494, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 219us/step - loss: 1.1313 - acc: 0.3375 - val_loss: 1.0949 - val_acc: 0.3848\n",
      "Epoch 3/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 1.1130 - acc: 0.3534- ETA: 0s - loss: 1.1107\n",
      "Epoch 00003: val_loss improved from 1.09494 to 1.09459, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 214us/step - loss: 1.1130 - acc: 0.3531 - val_loss: 1.0946 - val_acc: 0.3795\n",
      "Epoch 4/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 1.1123 - acc: 0.3476\n",
      "Epoch 00004: val_loss improved from 1.09459 to 1.09438, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 218us/step - loss: 1.1125 - acc: 0.3485 - val_loss: 1.0944 - val_acc: 0.3776\n",
      "Epoch 5/200\n",
      "5968/6216 [===========================>..] - ETA: 0s - loss: 1.1061 - acc: 0.3551\n",
      "Epoch 00005: val_loss improved from 1.09438 to 1.09406, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 221us/step - loss: 1.1064 - acc: 0.3557 - val_loss: 1.0941 - val_acc: 0.3791\n",
      "Epoch 6/200\n",
      "6016/6216 [============================>.] - ETA: 0s - loss: 1.1010 - acc: 0.3552\n",
      "Epoch 00006: val_loss improved from 1.09406 to 1.09337, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 219us/step - loss: 1.1009 - acc: 0.3541 - val_loss: 1.0934 - val_acc: 0.3810\n",
      "Epoch 7/200\n",
      "5984/6216 [===========================>..] - ETA: 0s - loss: 1.1022 - acc: 0.3585\n",
      "Epoch 00007: val_loss improved from 1.09337 to 1.09310, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 222us/step - loss: 1.1016 - acc: 0.3607 - val_loss: 1.0931 - val_acc: 0.3833\n",
      "Epoch 8/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 1.1004 - acc: 0.3607\n",
      "Epoch 00008: val_loss improved from 1.09310 to 1.09216, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 219us/step - loss: 1.0998 - acc: 0.3616 - val_loss: 1.0922 - val_acc: 0.3941\n",
      "Epoch 9/200\n",
      "6192/6216 [============================>.] - ETA: 0s - loss: 1.1004 - acc: 0.3630\n",
      "Epoch 00009: val_loss improved from 1.09216 to 1.09130, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 224us/step - loss: 1.1004 - acc: 0.3631 - val_loss: 1.0913 - val_acc: 0.3953\n",
      "Epoch 10/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 1.0971 - acc: 0.3675\n",
      "Epoch 00010: val_loss improved from 1.09130 to 1.09054, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 228us/step - loss: 1.0972 - acc: 0.3671 - val_loss: 1.0905 - val_acc: 0.3986\n",
      "Epoch 11/200\n",
      "5952/6216 [===========================>..] - ETA: 0s - loss: 1.0956 - acc: 0.3696\n",
      "Epoch 00011: val_loss improved from 1.09054 to 1.08928, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 221us/step - loss: 1.0955 - acc: 0.3697 - val_loss: 1.0893 - val_acc: 0.4039\n",
      "Epoch 12/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 1.0950 - acc: 0.3649\n",
      "Epoch 00012: val_loss improved from 1.08928 to 1.08831, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 222us/step - loss: 1.0951 - acc: 0.3650 - val_loss: 1.0883 - val_acc: 0.4092\n",
      "Epoch 13/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 1.0902 - acc: 0.3727\n",
      "Epoch 00013: val_loss improved from 1.08831 to 1.08630, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 225us/step - loss: 1.0905 - acc: 0.3724 - val_loss: 1.0863 - val_acc: 0.4170\n",
      "Epoch 14/200\n",
      "6048/6216 [============================>.] - ETA: 0s - loss: 1.0929 - acc: 0.3776\n",
      "Epoch 00014: val_loss improved from 1.08630 to 1.08553, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 220us/step - loss: 1.0930 - acc: 0.3766 - val_loss: 1.0855 - val_acc: 0.4223\n",
      "Epoch 15/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 1.0906 - acc: 0.3832\n",
      "Epoch 00015: val_loss improved from 1.08553 to 1.08424, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 227us/step - loss: 1.0908 - acc: 0.3829 - val_loss: 1.0842 - val_acc: 0.4245\n",
      "Epoch 16/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 1.0878 - acc: 0.3868\n",
      "Epoch 00016: val_loss improved from 1.08424 to 1.08220, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 226us/step - loss: 1.0879 - acc: 0.3861 - val_loss: 1.0822 - val_acc: 0.4276\n",
      "Epoch 17/200\n",
      "6208/6216 [============================>.] - ETA: 0s - loss: 1.0871 - acc: 0.3947\n",
      "Epoch 00017: val_loss improved from 1.08220 to 1.08070, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 226us/step - loss: 1.0870 - acc: 0.3951 - val_loss: 1.0807 - val_acc: 0.4276\n",
      "Epoch 18/200\n",
      "6192/6216 [============================>.] - ETA: 0s - loss: 1.0854 - acc: 0.3915\n",
      "Epoch 00018: val_loss improved from 1.08070 to 1.07952, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 221us/step - loss: 1.0855 - acc: 0.3912 - val_loss: 1.0795 - val_acc: 0.4298\n",
      "Epoch 19/200\n",
      "6208/6216 [============================>.] - ETA: 0s - loss: 1.0861 - acc: 0.3874\n",
      "Epoch 00019: val_loss improved from 1.07952 to 1.07804, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 223us/step - loss: 1.0862 - acc: 0.3872 - val_loss: 1.0780 - val_acc: 0.4283\n",
      "Epoch 20/200\n",
      "6208/6216 [============================>.] - ETA: 0s - loss: 1.0806 - acc: 0.3908\n",
      "Epoch 00020: val_loss improved from 1.07804 to 1.07566, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 223us/step - loss: 1.0808 - acc: 0.3906 - val_loss: 1.0757 - val_acc: 0.4324\n",
      "Epoch 21/200\n",
      "6016/6216 [============================>.] - ETA: 0s - loss: 1.0795 - acc: 0.4053\n",
      "Epoch 00021: val_loss improved from 1.07566 to 1.07402, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 221us/step - loss: 1.0796 - acc: 0.4054 - val_loss: 1.0740 - val_acc: 0.4362\n",
      "Epoch 22/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 1.0824 - acc: 0.3974\n",
      "Epoch 00022: val_loss improved from 1.07402 to 1.07186, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 220us/step - loss: 1.0823 - acc: 0.3985 - val_loss: 1.0719 - val_acc: 0.4351\n",
      "Epoch 23/200\n",
      "5936/6216 [===========================>..] - ETA: 0s - loss: 1.0800 - acc: 0.4089\n",
      "Epoch 00023: val_loss improved from 1.07186 to 1.07041, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 222us/step - loss: 1.0802 - acc: 0.4093 - val_loss: 1.0704 - val_acc: 0.4369\n",
      "Epoch 24/200\n",
      "5920/6216 [===========================>..] - ETA: 0s - loss: 1.0783 - acc: 0.4020\n",
      "Epoch 00024: val_loss improved from 1.07041 to 1.06882, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 221us/step - loss: 1.0788 - acc: 0.4003 - val_loss: 1.0688 - val_acc: 0.4388\n",
      "Epoch 25/200\n",
      "6048/6216 [============================>.] - ETA: 0s - loss: 1.0727 - acc: 0.4082\n",
      "Epoch 00025: val_loss improved from 1.06882 to 1.06631, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 230us/step - loss: 1.0734 - acc: 0.4070 - val_loss: 1.0663 - val_acc: 0.4407\n",
      "Epoch 26/200\n",
      "5984/6216 [===========================>..] - ETA: 0s - loss: 1.0758 - acc: 0.4079\n",
      "Epoch 00026: val_loss improved from 1.06631 to 1.06443, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 221us/step - loss: 1.0758 - acc: 0.4086 - val_loss: 1.0644 - val_acc: 0.4459\n",
      "Epoch 27/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 1.0734 - acc: 0.4075\n",
      "Epoch 00027: val_loss improved from 1.06443 to 1.06186, saving model to dl_emaus.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6216/6216 [==============================] - 1s 228us/step - loss: 1.0727 - acc: 0.4081 - val_loss: 1.0619 - val_acc: 0.4493\n",
      "Epoch 28/200\n",
      "6080/6216 [============================>.] - ETA: 0s - loss: 1.0776 - acc: 0.4023\n",
      "Epoch 00028: val_loss improved from 1.06186 to 1.06068, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 219us/step - loss: 1.0774 - acc: 0.4025 - val_loss: 1.0607 - val_acc: 0.4523\n",
      "Epoch 29/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 1.0633 - acc: 0.4294\n",
      "Epoch 00029: val_loss improved from 1.06068 to 1.05751, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 227us/step - loss: 1.0631 - acc: 0.4307 - val_loss: 1.0575 - val_acc: 0.4542\n",
      "Epoch 30/200\n",
      "6016/6216 [============================>.] - ETA: 0s - loss: 1.0694 - acc: 0.4121\n",
      "Epoch 00030: val_loss improved from 1.05751 to 1.05680, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 229us/step - loss: 1.0694 - acc: 0.4126 - val_loss: 1.0568 - val_acc: 0.4538\n",
      "Epoch 31/200\n",
      "5968/6216 [===========================>..] - ETA: 0s - loss: 1.0577 - acc: 0.4283\n",
      "Epoch 00031: val_loss improved from 1.05680 to 1.05383, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 230us/step - loss: 1.0589 - acc: 0.4257 - val_loss: 1.0538 - val_acc: 0.4565\n",
      "Epoch 32/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 1.0622 - acc: 0.4193\n",
      "Epoch 00032: val_loss improved from 1.05383 to 1.05117, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 229us/step - loss: 1.0622 - acc: 0.4188 - val_loss: 1.0512 - val_acc: 0.4610\n",
      "Epoch 33/200\n",
      "6176/6216 [============================>.] - ETA: 0s - loss: 1.0590 - acc: 0.4276\n",
      "Epoch 00033: val_loss improved from 1.05117 to 1.04801, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 224us/step - loss: 1.0589 - acc: 0.4286 - val_loss: 1.0480 - val_acc: 0.4681\n",
      "Epoch 34/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 1.0587 - acc: 0.4222\n",
      "Epoch 00034: val_loss improved from 1.04801 to 1.04610, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 226us/step - loss: 1.0581 - acc: 0.4231 - val_loss: 1.0461 - val_acc: 0.4681\n",
      "Epoch 35/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 1.0574 - acc: 0.4269\n",
      "Epoch 00035: val_loss improved from 1.04610 to 1.04447, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 223us/step - loss: 1.0578 - acc: 0.4266 - val_loss: 1.0445 - val_acc: 0.4688\n",
      "Epoch 36/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 1.0585 - acc: 0.4254\n",
      "Epoch 00036: val_loss improved from 1.04447 to 1.04300, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 227us/step - loss: 1.0580 - acc: 0.4266 - val_loss: 1.0430 - val_acc: 0.4700\n",
      "Epoch 37/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 1.0517 - acc: 0.4349\n",
      "Epoch 00037: val_loss improved from 1.04300 to 1.04072, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 226us/step - loss: 1.0518 - acc: 0.4345 - val_loss: 1.0407 - val_acc: 0.4696\n",
      "Epoch 38/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 1.0507 - acc: 0.4354\n",
      "Epoch 00038: val_loss improved from 1.04072 to 1.03933, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 224us/step - loss: 1.0512 - acc: 0.4347 - val_loss: 1.0393 - val_acc: 0.4707\n",
      "Epoch 39/200\n",
      "6192/6216 [============================>.] - ETA: 0s - loss: 1.0546 - acc: 0.4346\n",
      "Epoch 00039: val_loss improved from 1.03933 to 1.03849, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 224us/step - loss: 1.0545 - acc: 0.4345 - val_loss: 1.0385 - val_acc: 0.4726\n",
      "Epoch 40/200\n",
      "6176/6216 [============================>.] - ETA: 0s - loss: 1.0454 - acc: 0.4462\n",
      "Epoch 00040: val_loss improved from 1.03849 to 1.03484, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 225us/step - loss: 1.0459 - acc: 0.4456 - val_loss: 1.0348 - val_acc: 0.4756\n",
      "Epoch 41/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 1.0457 - acc: 0.4411\n",
      "Epoch 00041: val_loss improved from 1.03484 to 1.03334, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 216us/step - loss: 1.0452 - acc: 0.4408 - val_loss: 1.0333 - val_acc: 0.4741\n",
      "Epoch 42/200\n",
      "5984/6216 [===========================>..] - ETA: 0s - loss: 1.0413 - acc: 0.4492\n",
      "Epoch 00042: val_loss improved from 1.03334 to 1.03072, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 220us/step - loss: 1.0417 - acc: 0.4501 - val_loss: 1.0307 - val_acc: 0.4775\n",
      "Epoch 43/200\n",
      "5936/6216 [===========================>..] - ETA: 0s - loss: 1.0415 - acc: 0.4471\n",
      "Epoch 00043: val_loss improved from 1.03072 to 1.03004, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 220us/step - loss: 1.0412 - acc: 0.4464 - val_loss: 1.0300 - val_acc: 0.4764\n",
      "Epoch 44/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 1.0371 - acc: 0.4429\n",
      "Epoch 00044: val_loss improved from 1.03004 to 1.02725, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 227us/step - loss: 1.0376 - acc: 0.4431 - val_loss: 1.0272 - val_acc: 0.4775\n",
      "Epoch 45/200\n",
      "5968/6216 [===========================>..] - ETA: 0s - loss: 1.0382 - acc: 0.4442\n",
      "Epoch 00045: val_loss improved from 1.02725 to 1.02575, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 218us/step - loss: 1.0394 - acc: 0.4422 - val_loss: 1.0258 - val_acc: 0.4801\n",
      "Epoch 46/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 1.0378 - acc: 0.4466\n",
      "Epoch 00046: val_loss improved from 1.02575 to 1.02446, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 219us/step - loss: 1.0379 - acc: 0.4472 - val_loss: 1.0245 - val_acc: 0.4820\n",
      "Epoch 47/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 1.0319 - acc: 0.4557\n",
      "Epoch 00047: val_loss improved from 1.02446 to 1.02308, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 225us/step - loss: 1.0315 - acc: 0.4564 - val_loss: 1.0231 - val_acc: 0.4824\n",
      "Epoch 48/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 1.0340 - acc: 0.4655\n",
      "Epoch 00048: val_loss improved from 1.02308 to 1.02120, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 222us/step - loss: 1.0339 - acc: 0.4643 - val_loss: 1.0212 - val_acc: 0.4816\n",
      "Epoch 49/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 1.0356 - acc: 0.4498\n",
      "Epoch 00049: val_loss improved from 1.02120 to 1.02069, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 221us/step - loss: 1.0346 - acc: 0.4517 - val_loss: 1.0207 - val_acc: 0.4861\n",
      "Epoch 50/200\n",
      "5936/6216 [===========================>..] - ETA: 0s - loss: 1.0311 - acc: 0.4537\n",
      "Epoch 00050: val_loss improved from 1.02069 to 1.01941, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 221us/step - loss: 1.0312 - acc: 0.4519 - val_loss: 1.0194 - val_acc: 0.4854\n",
      "Epoch 51/200\n",
      "6208/6216 [============================>.] - ETA: 0s - loss: 1.0306 - acc: 0.4573\n",
      "Epoch 00051: val_loss improved from 1.01941 to 1.01847, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 226us/step - loss: 1.0307 - acc: 0.4570 - val_loss: 1.0185 - val_acc: 0.4846\n",
      "Epoch 52/200\n",
      "6000/6216 [===========================>..] - ETA: 0s - loss: 1.0292 - acc: 0.4555\n",
      "Epoch 00052: val_loss improved from 1.01847 to 1.01771, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 218us/step - loss: 1.0289 - acc: 0.4577 - val_loss: 1.0177 - val_acc: 0.4880\n",
      "Epoch 53/200\n",
      "5920/6216 [===========================>..] - ETA: 0s - loss: 1.0193 - acc: 0.4649\n",
      "Epoch 00053: val_loss improved from 1.01771 to 1.01484, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 219us/step - loss: 1.0196 - acc: 0.4654 - val_loss: 1.0148 - val_acc: 0.4895\n",
      "Epoch 54/200\n",
      "5968/6216 [===========================>..] - ETA: 0s - loss: 1.0172 - acc: 0.4767\n",
      "Epoch 00054: val_loss improved from 1.01484 to 1.01399, saving model to dl_emaus.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6216/6216 [==============================] - 1s 218us/step - loss: 1.0200 - acc: 0.4751 - val_loss: 1.0140 - val_acc: 0.4887\n",
      "Epoch 55/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 1.0203 - acc: 0.4600- ETA: 0s - loss: 1.0206 - acc: 0.45\n",
      "Epoch 00055: val_loss improved from 1.01399 to 1.01360, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 227us/step - loss: 1.0211 - acc: 0.4582 - val_loss: 1.0136 - val_acc: 0.4936\n",
      "Epoch 56/200\n",
      "6048/6216 [============================>.] - ETA: 0s - loss: 1.0197 - acc: 0.4658\n",
      "Epoch 00056: val_loss improved from 1.01360 to 1.01204, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 226us/step - loss: 1.0197 - acc: 0.4654 - val_loss: 1.0120 - val_acc: 0.4932\n",
      "Epoch 57/200\n",
      "5968/6216 [===========================>..] - ETA: 0s - loss: 1.0179 - acc: 0.4658\n",
      "Epoch 00057: val_loss improved from 1.01204 to 1.01088, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 224us/step - loss: 1.0187 - acc: 0.4661 - val_loss: 1.0109 - val_acc: 0.4876\n",
      "Epoch 58/200\n",
      "6176/6216 [============================>.] - ETA: 0s - loss: 1.0172 - acc: 0.4710\n",
      "Epoch 00058: val_loss improved from 1.01088 to 1.01047, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 227us/step - loss: 1.0171 - acc: 0.4710 - val_loss: 1.0105 - val_acc: 0.4940\n",
      "Epoch 59/200\n",
      "6080/6216 [============================>.] - ETA: 0s - loss: 1.0133 - acc: 0.4648\n",
      "Epoch 00059: val_loss improved from 1.01047 to 1.00961, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 229us/step - loss: 1.0130 - acc: 0.4656 - val_loss: 1.0096 - val_acc: 0.4944\n",
      "Epoch 60/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 1.0064 - acc: 0.4749\n",
      "Epoch 00060: val_loss improved from 1.00961 to 1.00700, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 2s 274us/step - loss: 1.0060 - acc: 0.4749 - val_loss: 1.0070 - val_acc: 0.4932\n",
      "Epoch 61/200\n",
      "6080/6216 [============================>.] - ETA: 0s - loss: 1.0099 - acc: 0.4730\n",
      "Epoch 00061: val_loss improved from 1.00700 to 1.00645, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 2s 275us/step - loss: 1.0102 - acc: 0.4728 - val_loss: 1.0064 - val_acc: 0.4947\n",
      "Epoch 62/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 1.0100 - acc: 0.4769\n",
      "Epoch 00062: val_loss improved from 1.00645 to 1.00613, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 2s 271us/step - loss: 1.0097 - acc: 0.4773 - val_loss: 1.0061 - val_acc: 0.4959\n",
      "Epoch 63/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 1.0069 - acc: 0.4777\n",
      "Epoch 00063: val_loss improved from 1.00613 to 1.00587, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 2s 254us/step - loss: 1.0063 - acc: 0.4780 - val_loss: 1.0059 - val_acc: 0.4996\n",
      "Epoch 64/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 1.0053 - acc: 0.4715\n",
      "Epoch 00064: val_loss improved from 1.00587 to 1.00498, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 2s 251us/step - loss: 1.0059 - acc: 0.4727 - val_loss: 1.0050 - val_acc: 0.4974\n",
      "Epoch 65/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9989 - acc: 0.4807\n",
      "Epoch 00065: val_loss improved from 1.00498 to 1.00373, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 240us/step - loss: 0.9994 - acc: 0.4804 - val_loss: 1.0037 - val_acc: 0.4996\n",
      "Epoch 66/200\n",
      "6000/6216 [===========================>..] - ETA: 0s - loss: 1.0034 - acc: 0.4800\n",
      "Epoch 00066: val_loss improved from 1.00373 to 1.00317, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 236us/step - loss: 1.0036 - acc: 0.4799 - val_loss: 1.0032 - val_acc: 0.5008\n",
      "Epoch 67/200\n",
      "5936/6216 [===========================>..] - ETA: 0s - loss: 0.9993 - acc: 0.4810\n",
      "Epoch 00067: val_loss improved from 1.00317 to 1.00250, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 216us/step - loss: 0.9978 - acc: 0.4817 - val_loss: 1.0025 - val_acc: 0.4996\n",
      "Epoch 68/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 0.9964 - acc: 0.4881\n",
      "Epoch 00068: val_loss improved from 1.00250 to 1.00183, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 193us/step - loss: 0.9965 - acc: 0.4894 - val_loss: 1.0018 - val_acc: 0.5004\n",
      "Epoch 69/200\n",
      "5984/6216 [===========================>..] - ETA: 0s - loss: 1.0006 - acc: 0.4843\n",
      "Epoch 00069: val_loss improved from 1.00183 to 1.00055, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 189us/step - loss: 1.0001 - acc: 0.4850 - val_loss: 1.0005 - val_acc: 0.5019\n",
      "Epoch 70/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9950 - acc: 0.4870\n",
      "Epoch 00070: val_loss improved from 1.00055 to 0.99979, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 219us/step - loss: 0.9949 - acc: 0.4871 - val_loss: 0.9998 - val_acc: 0.5000\n",
      "Epoch 71/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 0.9986 - acc: 0.4843\n",
      "Epoch 00071: val_loss improved from 0.99979 to 0.99966, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 188us/step - loss: 1.0012 - acc: 0.4826 - val_loss: 0.9997 - val_acc: 0.5008\n",
      "Epoch 72/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9965 - acc: 0.4868\n",
      "Epoch 00072: val_loss improved from 0.99966 to 0.99924, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 186us/step - loss: 0.9969 - acc: 0.4862 - val_loss: 0.9992 - val_acc: 0.5004\n",
      "Epoch 73/200\n",
      "5952/6216 [===========================>..] - ETA: 0s - loss: 0.9937 - acc: 0.4898\n",
      "Epoch 00073: val_loss improved from 0.99924 to 0.99874, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 206us/step - loss: 0.9937 - acc: 0.4881 - val_loss: 0.9987 - val_acc: 0.5004\n",
      "Epoch 74/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9914 - acc: 0.4908\n",
      "Epoch 00074: val_loss improved from 0.99874 to 0.99834, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 201us/step - loss: 0.9911 - acc: 0.4907 - val_loss: 0.9983 - val_acc: 0.4977\n",
      "Epoch 75/200\n",
      "6080/6216 [============================>.] - ETA: 0s - loss: 0.9880 - acc: 0.4982\n",
      "Epoch 00075: val_loss improved from 0.99834 to 0.99740, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 209us/step - loss: 0.9882 - acc: 0.4986 - val_loss: 0.9974 - val_acc: 0.4966\n",
      "Epoch 76/200\n",
      "6000/6216 [===========================>..] - ETA: 0s - loss: 0.9922 - acc: 0.4913\n",
      "Epoch 00076: val_loss improved from 0.99740 to 0.99608, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 189us/step - loss: 0.9919 - acc: 0.4918 - val_loss: 0.9961 - val_acc: 0.4985\n",
      "Epoch 77/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9927 - acc: 0.4864\n",
      "Epoch 00077: val_loss improved from 0.99608 to 0.99586, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 185us/step - loss: 0.9918 - acc: 0.4873 - val_loss: 0.9959 - val_acc: 0.5023\n",
      "Epoch 78/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9851 - acc: 0.4925\n",
      "Epoch 00078: val_loss improved from 0.99586 to 0.99535, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 186us/step - loss: 0.9841 - acc: 0.4937 - val_loss: 0.9954 - val_acc: 0.4985\n",
      "Epoch 79/200\n",
      "6048/6216 [============================>.] - ETA: 0s - loss: 0.9895 - acc: 0.4909\n",
      "Epoch 00079: val_loss improved from 0.99535 to 0.99465, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 209us/step - loss: 0.9900 - acc: 0.4895 - val_loss: 0.9946 - val_acc: 0.5023\n",
      "Epoch 80/200\n",
      "5984/6216 [===========================>..] - ETA: 0s - loss: 0.9840 - acc: 0.4963\n",
      "Epoch 00080: val_loss improved from 0.99465 to 0.99452, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 192us/step - loss: 0.9852 - acc: 0.4957 - val_loss: 0.9945 - val_acc: 0.5023\n",
      "Epoch 81/200\n",
      "5984/6216 [===========================>..] - ETA: 0s - loss: 0.9822 - acc: 0.5040\n",
      "Epoch 00081: val_loss improved from 0.99452 to 0.99331, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 203us/step - loss: 0.9815 - acc: 0.5045 - val_loss: 0.9933 - val_acc: 0.5023\n",
      "Epoch 82/200\n",
      "6192/6216 [============================>.] - ETA: 0s - loss: 0.9805 - acc: 0.5013\n",
      "Epoch 00082: val_loss improved from 0.99331 to 0.99292, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 2s 301us/step - loss: 0.9805 - acc: 0.5011 - val_loss: 0.9929 - val_acc: 0.5038\n",
      "Epoch 83/200\n",
      "6000/6216 [===========================>..] - ETA: 0s - loss: 0.9862 - acc: 0.5000\n",
      "Epoch 00083: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 217us/step - loss: 0.9860 - acc: 0.4990 - val_loss: 0.9934 - val_acc: 0.5015\n",
      "Epoch 84/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 0.9703 - acc: 0.5048\n",
      "Epoch 00084: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 231us/step - loss: 0.9695 - acc: 0.5053 - val_loss: 0.9936 - val_acc: 0.5008\n",
      "Epoch 85/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 0.9750 - acc: 0.4988\n",
      "Epoch 00085: val_loss did not improve\n",
      "6216/6216 [==============================] - 2s 282us/step - loss: 0.9752 - acc: 0.4984 - val_loss: 0.9936 - val_acc: 0.5015\n",
      "Epoch 86/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9814 - acc: 0.5007\n",
      "Epoch 00086: val_loss did not improve\n",
      "6216/6216 [==============================] - 2s 303us/step - loss: 0.9818 - acc: 0.5014 - val_loss: 0.9940 - val_acc: 0.5023\n",
      "Epoch 87/200\n",
      "5952/6216 [===========================>..] - ETA: 0s - loss: 0.9758 - acc: 0.5017\n",
      "Epoch 00087: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 236us/step - loss: 0.9766 - acc: 0.5006 - val_loss: 0.9931 - val_acc: 0.5019\n",
      "Epoch 88/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9709 - acc: 0.5055\n",
      "Epoch 00088: val_loss improved from 0.99292 to 0.99227, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 231us/step - loss: 0.9703 - acc: 0.5055 - val_loss: 0.9923 - val_acc: 0.5019\n",
      "Epoch 89/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 0.9744 - acc: 0.5060\n",
      "Epoch 00089: val_loss did not improve\n",
      "6216/6216 [==============================] - 2s 266us/step - loss: 0.9731 - acc: 0.5082 - val_loss: 0.9925 - val_acc: 0.5045\n",
      "Epoch 90/200\n",
      "6000/6216 [===========================>..] - ETA: 0s - loss: 0.9689 - acc: 0.5057\n",
      "Epoch 00090: val_loss improved from 0.99227 to 0.99156, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 226us/step - loss: 0.9712 - acc: 0.5035 - val_loss: 0.9916 - val_acc: 0.5023\n",
      "Epoch 91/200\n",
      "6016/6216 [============================>.] - ETA: 0s - loss: 0.9689 - acc: 0.5133\n",
      "Epoch 00091: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 194us/step - loss: 0.9689 - acc: 0.5121 - val_loss: 0.9916 - val_acc: 0.5041\n",
      "Epoch 92/200\n",
      "6048/6216 [============================>.] - ETA: 0s - loss: 0.9736 - acc: 0.4957\n",
      "Epoch 00092: val_loss improved from 0.99156 to 0.99115, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 188us/step - loss: 0.9720 - acc: 0.4979 - val_loss: 0.9911 - val_acc: 0.5071\n",
      "Epoch 93/200\n",
      "6208/6216 [============================>.] - ETA: 0s - loss: 0.9692 - acc: 0.5100\n",
      "Epoch 00093: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 190us/step - loss: 0.9691 - acc: 0.5098 - val_loss: 0.9912 - val_acc: 0.5030\n",
      "Epoch 94/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 0.9645 - acc: 0.5083\n",
      "Epoch 00094: val_loss improved from 0.99115 to 0.99024, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 188us/step - loss: 0.9638 - acc: 0.5093 - val_loss: 0.9902 - val_acc: 0.5038\n",
      "Epoch 95/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9731 - acc: 0.5076\n",
      "Epoch 00095: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9730 - acc: 0.5080 - val_loss: 0.9909 - val_acc: 0.5008\n",
      "Epoch 96/200\n",
      "6176/6216 [============================>.] - ETA: 0s - loss: 0.9675 - acc: 0.5152\n",
      "Epoch 00096: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9675 - acc: 0.5151 - val_loss: 0.9908 - val_acc: 0.5071\n",
      "Epoch 97/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9671 - acc: 0.5192\n",
      "Epoch 00097: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.9669 - acc: 0.5187 - val_loss: 0.9905 - val_acc: 0.5049\n",
      "Epoch 98/200\n",
      "5968/6216 [===========================>..] - ETA: 0s - loss: 0.9643 - acc: 0.5107\n",
      "Epoch 00098: val_loss improved from 0.99024 to 0.99019, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 190us/step - loss: 0.9643 - acc: 0.5106 - val_loss: 0.9902 - val_acc: 0.5086\n",
      "Epoch 99/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9617 - acc: 0.5110\n",
      "Epoch 00099: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9626 - acc: 0.5103 - val_loss: 0.9907 - val_acc: 0.5086\n",
      "Epoch 100/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9645 - acc: 0.5163\n",
      "Epoch 00100: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9655 - acc: 0.5154 - val_loss: 0.9902 - val_acc: 0.5064\n",
      "Epoch 101/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9620 - acc: 0.5155\n",
      "Epoch 00101: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9624 - acc: 0.5142 - val_loss: 0.9904 - val_acc: 0.5045\n",
      "Epoch 102/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9605 - acc: 0.5271\n",
      "Epoch 00102: val_loss improved from 0.99019 to 0.98959, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 184us/step - loss: 0.9608 - acc: 0.5267 - val_loss: 0.9896 - val_acc: 0.5056\n",
      "Epoch 103/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9550 - acc: 0.5186\n",
      "Epoch 00103: val_loss improved from 0.98959 to 0.98915, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 185us/step - loss: 0.9554 - acc: 0.5188 - val_loss: 0.9891 - val_acc: 0.5075\n",
      "Epoch 104/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9570 - acc: 0.5250\n",
      "Epoch 00104: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9568 - acc: 0.5256 - val_loss: 0.9897 - val_acc: 0.5049\n",
      "Epoch 105/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9483 - acc: 0.5362\n",
      "Epoch 00105: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9479 - acc: 0.5370 - val_loss: 0.9897 - val_acc: 0.5038\n",
      "Epoch 106/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 0.9574 - acc: 0.5136\n",
      "Epoch 00106: val_loss improved from 0.98915 to 0.98865, saving model to dl_emaus.hdf5\n",
      "6216/6216 [==============================] - 1s 184us/step - loss: 0.9563 - acc: 0.5143 - val_loss: 0.9887 - val_acc: 0.5049\n",
      "Epoch 107/200\n",
      "5968/6216 [===========================>..] - ETA: 0s - loss: 0.9531 - acc: 0.5261\n",
      "Epoch 00107: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 185us/step - loss: 0.9536 - acc: 0.5248 - val_loss: 0.9890 - val_acc: 0.5030\n",
      "Epoch 108/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9553 - acc: 0.5175\n",
      "Epoch 00108: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9559 - acc: 0.5167 - val_loss: 0.9896 - val_acc: 0.5056\n",
      "Epoch 109/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9486 - acc: 0.5203\n",
      "Epoch 00109: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9493 - acc: 0.5201 - val_loss: 0.9902 - val_acc: 0.5026\n",
      "Epoch 110/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9517 - acc: 0.5249\n",
      "Epoch 00110: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9513 - acc: 0.5240 - val_loss: 0.9892 - val_acc: 0.5064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9496 - acc: 0.5223\n",
      "Epoch 00111: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9486 - acc: 0.5230 - val_loss: 0.9891 - val_acc: 0.5064\n",
      "Epoch 112/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9483 - acc: 0.5250\n",
      "Epoch 00112: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9479 - acc: 0.5249 - val_loss: 0.9898 - val_acc: 0.5060\n",
      "Epoch 113/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9519 - acc: 0.5238\n",
      "Epoch 00113: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9520 - acc: 0.5241 - val_loss: 0.9908 - val_acc: 0.5034\n",
      "Epoch 114/200\n",
      "6176/6216 [============================>.] - ETA: 0s - loss: 0.9481 - acc: 0.5296\n",
      "Epoch 00114: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9484 - acc: 0.5298 - val_loss: 0.9901 - val_acc: 0.5049\n",
      "Epoch 115/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9473 - acc: 0.5206\n",
      "Epoch 00115: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9470 - acc: 0.5204 - val_loss: 0.9901 - val_acc: 0.5064\n",
      "Epoch 116/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9395 - acc: 0.5303\n",
      "Epoch 00116: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9392 - acc: 0.5306 - val_loss: 0.9906 - val_acc: 0.5053\n",
      "Epoch 117/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 0.9379 - acc: 0.5339\n",
      "Epoch 00117: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.9400 - acc: 0.5336 - val_loss: 0.9913 - val_acc: 0.5053\n",
      "Epoch 118/200\n",
      "6192/6216 [============================>.] - ETA: 0s - loss: 0.9410 - acc: 0.5302\n",
      "Epoch 00118: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9409 - acc: 0.5298 - val_loss: 0.9904 - val_acc: 0.5086\n",
      "Epoch 119/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9453 - acc: 0.5243\n",
      "Epoch 00119: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9451 - acc: 0.5243 - val_loss: 0.9891 - val_acc: 0.5090\n",
      "Epoch 120/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9458 - acc: 0.5262\n",
      "Epoch 00120: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9465 - acc: 0.5262 - val_loss: 0.9890 - val_acc: 0.5116\n",
      "Epoch 121/200\n",
      "6192/6216 [============================>.] - ETA: 0s - loss: 0.9375 - acc: 0.5329\n",
      "Epoch 00121: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9380 - acc: 0.5325 - val_loss: 0.9897 - val_acc: 0.5045\n",
      "Epoch 122/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9324 - acc: 0.5319\n",
      "Epoch 00122: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9328 - acc: 0.5312 - val_loss: 0.9899 - val_acc: 0.5064\n",
      "Epoch 123/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 0.9356 - acc: 0.5356\n",
      "Epoch 00123: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9361 - acc: 0.5351 - val_loss: 0.9908 - val_acc: 0.5068\n",
      "Epoch 124/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9370 - acc: 0.5317\n",
      "Epoch 00124: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9388 - acc: 0.5322 - val_loss: 0.9900 - val_acc: 0.5090\n",
      "Epoch 125/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9418 - acc: 0.5308\n",
      "Epoch 00125: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9411 - acc: 0.5307 - val_loss: 0.9903 - val_acc: 0.5090\n",
      "Epoch 126/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9345 - acc: 0.5442\n",
      "Epoch 00126: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9340 - acc: 0.5430 - val_loss: 0.9899 - val_acc: 0.5101\n",
      "Epoch 127/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9301 - acc: 0.5320\n",
      "Epoch 00127: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9308 - acc: 0.5317 - val_loss: 0.9898 - val_acc: 0.5079\n",
      "Epoch 128/200\n",
      "6192/6216 [============================>.] - ETA: 0s - loss: 0.9315 - acc: 0.5300\n",
      "Epoch 00128: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9321 - acc: 0.5298 - val_loss: 0.9907 - val_acc: 0.5075\n",
      "Epoch 129/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9312 - acc: 0.5392\n",
      "Epoch 00129: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9327 - acc: 0.5380 - val_loss: 0.9905 - val_acc: 0.5090\n",
      "Epoch 130/200\n",
      "6176/6216 [============================>.] - ETA: 0s - loss: 0.9240 - acc: 0.5402\n",
      "Epoch 00130: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9237 - acc: 0.5401 - val_loss: 0.9914 - val_acc: 0.5094\n",
      "Epoch 131/200\n",
      "6176/6216 [============================>.] - ETA: 0s - loss: 0.9305 - acc: 0.5468\n",
      "Epoch 00131: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9310 - acc: 0.5463 - val_loss: 0.9920 - val_acc: 0.5060\n",
      "Epoch 132/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9313 - acc: 0.5473\n",
      "Epoch 00132: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9316 - acc: 0.5467 - val_loss: 0.9909 - val_acc: 0.5075\n",
      "Epoch 133/200\n",
      "6176/6216 [============================>.] - ETA: 0s - loss: 0.9242 - acc: 0.5515\n",
      "Epoch 00133: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9242 - acc: 0.5516 - val_loss: 0.9918 - val_acc: 0.5056\n",
      "Epoch 134/200\n",
      "5952/6216 [===========================>..] - ETA: 0s - loss: 0.9291 - acc: 0.5366\n",
      "Epoch 00134: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 184us/step - loss: 0.9287 - acc: 0.5388 - val_loss: 0.9924 - val_acc: 0.5060\n",
      "Epoch 135/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9296 - acc: 0.5344\n",
      "Epoch 00135: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9299 - acc: 0.5357 - val_loss: 0.9913 - val_acc: 0.5071\n",
      "Epoch 136/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9264 - acc: 0.5483\n",
      "Epoch 00136: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9272 - acc: 0.5475 - val_loss: 0.9921 - val_acc: 0.5038\n",
      "Epoch 137/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9220 - acc: 0.5447\n",
      "Epoch 00137: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9220 - acc: 0.5446 - val_loss: 0.9925 - val_acc: 0.5034\n",
      "Epoch 138/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9227 - acc: 0.5412\n",
      "Epoch 00138: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9228 - acc: 0.5418 - val_loss: 0.9930 - val_acc: 0.5049\n",
      "Epoch 139/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9187 - acc: 0.5505\n",
      "Epoch 00139: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9194 - acc: 0.5495 - val_loss: 0.9927 - val_acc: 0.5060\n",
      "Epoch 140/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9143 - acc: 0.5488\n",
      "Epoch 00140: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9140 - acc: 0.5499 - val_loss: 0.9936 - val_acc: 0.5079\n",
      "Epoch 141/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9209 - acc: 0.5474\n",
      "Epoch 00141: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9203 - acc: 0.5475 - val_loss: 0.9934 - val_acc: 0.5079\n",
      "Epoch 142/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9150 - acc: 0.5543\n",
      "Epoch 00142: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9154 - acc: 0.5536 - val_loss: 0.9931 - val_acc: 0.5090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9207 - acc: 0.5514\n",
      "Epoch 00143: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9212 - acc: 0.5510 - val_loss: 0.9916 - val_acc: 0.5079\n",
      "Epoch 144/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9176 - acc: 0.5441\n",
      "Epoch 00144: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9176 - acc: 0.5438 - val_loss: 0.9919 - val_acc: 0.5083\n",
      "Epoch 145/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.9100 - acc: 0.5568\n",
      "Epoch 00145: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9106 - acc: 0.5565 - val_loss: 0.9931 - val_acc: 0.5094\n",
      "Epoch 146/200\n",
      "5904/6216 [===========================>..] - ETA: 0s - loss: 0.9192 - acc: 0.5486\n",
      "Epoch 00146: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.9174 - acc: 0.5505 - val_loss: 0.9933 - val_acc: 0.5053\n",
      "Epoch 147/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9161 - acc: 0.5489\n",
      "Epoch 00147: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9161 - acc: 0.5489 - val_loss: 0.9925 - val_acc: 0.5045\n",
      "Epoch 148/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9086 - acc: 0.5586\n",
      "Epoch 00148: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9074 - acc: 0.5594 - val_loss: 0.9926 - val_acc: 0.5038\n",
      "Epoch 149/200\n",
      "6176/6216 [============================>.] - ETA: 0s - loss: 0.9069 - acc: 0.5597\n",
      "Epoch 00149: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 179us/step - loss: 0.9070 - acc: 0.5598 - val_loss: 0.9936 - val_acc: 0.5015\n",
      "Epoch 150/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.9098 - acc: 0.5555\n",
      "Epoch 00150: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9099 - acc: 0.5544 - val_loss: 0.9937 - val_acc: 0.5053\n",
      "Epoch 151/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9084 - acc: 0.5523\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 8.999999772640876e-05.\n",
      "\n",
      "Epoch 00151: val_loss did not improve\n",
      "6216/6216 [==============================] - 2s 245us/step - loss: 0.9070 - acc: 0.5531 - val_loss: 0.9945 - val_acc: 0.5023\n",
      "Epoch 152/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9031 - acc: 0.5504\n",
      "Epoch 00152: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9025 - acc: 0.5513 - val_loss: 0.9970 - val_acc: 0.5083\n",
      "Epoch 153/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9091 - acc: 0.5502\n",
      "Epoch 00153: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.9111 - acc: 0.5497 - val_loss: 0.9966 - val_acc: 0.5049\n",
      "Epoch 154/200\n",
      "5936/6216 [===========================>..] - ETA: 0s - loss: 0.9111 - acc: 0.5534\n",
      "Epoch 00154: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 185us/step - loss: 0.9103 - acc: 0.5537 - val_loss: 0.9980 - val_acc: 0.5008\n",
      "Epoch 155/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9091 - acc: 0.5546\n",
      "Epoch 00155: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9086 - acc: 0.5547 - val_loss: 0.9970 - val_acc: 0.5015\n",
      "Epoch 156/200\n",
      "6080/6216 [============================>.] - ETA: 0s - loss: 0.9031 - acc: 0.5622\n",
      "Epoch 00156: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9026 - acc: 0.5615 - val_loss: 0.9975 - val_acc: 0.5053\n",
      "Epoch 157/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9070 - acc: 0.5561\n",
      "Epoch 00157: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9058 - acc: 0.5568 - val_loss: 0.9986 - val_acc: 0.5056\n",
      "Epoch 158/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8960 - acc: 0.5604\n",
      "Epoch 00158: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8961 - acc: 0.5595 - val_loss: 0.9984 - val_acc: 0.5041\n",
      "Epoch 159/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.9010 - acc: 0.5596\n",
      "Epoch 00159: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9029 - acc: 0.5595 - val_loss: 0.9989 - val_acc: 0.5038\n",
      "Epoch 160/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.8966 - acc: 0.5684\n",
      "Epoch 00160: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8974 - acc: 0.5690 - val_loss: 0.9998 - val_acc: 0.5064\n",
      "Epoch 161/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9002 - acc: 0.5612\n",
      "Epoch 00161: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.9013 - acc: 0.5600 - val_loss: 1.0000 - val_acc: 0.5071\n",
      "Epoch 162/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.8985 - acc: 0.5578\n",
      "Epoch 00162: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8975 - acc: 0.5586 - val_loss: 1.0008 - val_acc: 0.5086\n",
      "Epoch 163/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 0.8890 - acc: 0.5597\n",
      "Epoch 00163: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8904 - acc: 0.5606 - val_loss: 1.0018 - val_acc: 0.5056\n",
      "Epoch 164/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.9008 - acc: 0.5576\n",
      "Epoch 00164: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8995 - acc: 0.5587 - val_loss: 1.0013 - val_acc: 0.5023\n",
      "Epoch 165/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8973 - acc: 0.5648\n",
      "Epoch 00165: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8980 - acc: 0.5644 - val_loss: 1.0008 - val_acc: 0.5053\n",
      "Epoch 166/200\n",
      "6208/6216 [============================>.] - ETA: 0s - loss: 0.8995 - acc: 0.5693\n",
      "Epoch 00166: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 204us/step - loss: 0.8995 - acc: 0.5693 - val_loss: 1.0006 - val_acc: 0.5083\n",
      "Epoch 167/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8991 - acc: 0.5687\n",
      "Epoch 00167: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8987 - acc: 0.5687 - val_loss: 1.0009 - val_acc: 0.5041\n",
      "Epoch 168/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8862 - acc: 0.5679- ETA: 0s - loss: 0.8814 - acc: 0\n",
      "Epoch 00168: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8879 - acc: 0.5650 - val_loss: 1.0018 - val_acc: 0.5049\n",
      "Epoch 169/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 0.8883 - acc: 0.5679\n",
      "Epoch 00169: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8877 - acc: 0.5685 - val_loss: 1.0025 - val_acc: 0.5064\n",
      "Epoch 170/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8958 - acc: 0.5650\n",
      "Epoch 00170: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8955 - acc: 0.5652 - val_loss: 1.0010 - val_acc: 0.5090\n",
      "Epoch 171/200\n",
      "6080/6216 [============================>.] - ETA: 0s - loss: 0.8908 - acc: 0.5623\n",
      "Epoch 00171: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 184us/step - loss: 0.8896 - acc: 0.5632 - val_loss: 1.0021 - val_acc: 0.5071\n",
      "Epoch 172/200\n",
      "5936/6216 [===========================>..] - ETA: 0s - loss: 0.8937 - acc: 0.5618\n",
      "Epoch 00172: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 186us/step - loss: 0.8935 - acc: 0.5631 - val_loss: 1.0033 - val_acc: 0.5083\n",
      "Epoch 173/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8850 - acc: 0.5651\n",
      "Epoch 00173: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8856 - acc: 0.5655 - val_loss: 1.0034 - val_acc: 0.5041\n",
      "Epoch 174/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 0.8832 - acc: 0.5760\n",
      "Epoch 00174: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8826 - acc: 0.5775 - val_loss: 1.0071 - val_acc: 0.5075\n",
      "Epoch 175/200\n",
      "6048/6216 [============================>.] - ETA: 0s - loss: 0.8977 - acc: 0.5671\n",
      "Epoch 00175: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8988 - acc: 0.5666 - val_loss: 1.0053 - val_acc: 0.5049\n",
      "Epoch 176/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 0.8821 - acc: 0.5757\n",
      "Epoch 00176: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8823 - acc: 0.5746 - val_loss: 1.0054 - val_acc: 0.5056\n",
      "Epoch 177/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.8785 - acc: 0.5710\n",
      "Epoch 00177: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.8794 - acc: 0.5705 - val_loss: 1.0063 - val_acc: 0.5079\n",
      "Epoch 178/200\n",
      "6016/6216 [============================>.] - ETA: 0s - loss: 0.8910 - acc: 0.5665\n",
      "Epoch 00178: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 183us/step - loss: 0.8902 - acc: 0.5671 - val_loss: 1.0055 - val_acc: 0.5109\n",
      "Epoch 179/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8849 - acc: 0.5692\n",
      "Epoch 00179: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8836 - acc: 0.5713 - val_loss: 1.0069 - val_acc: 0.5045\n",
      "Epoch 180/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8743 - acc: 0.5822\n",
      "Epoch 00180: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8758 - acc: 0.5795 - val_loss: 1.0078 - val_acc: 0.5090\n",
      "Epoch 181/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.8821 - acc: 0.5780\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 8.100000122794882e-05.\n",
      "\n",
      "Epoch 00181: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8834 - acc: 0.5775 - val_loss: 1.0083 - val_acc: 0.5090\n",
      "Epoch 182/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.8923 - acc: 0.5671\n",
      "Epoch 00182: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8918 - acc: 0.5664 - val_loss: 1.0062 - val_acc: 0.5094\n",
      "Epoch 183/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8850 - acc: 0.5696\n",
      "Epoch 00183: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 180us/step - loss: 0.8848 - acc: 0.5695 - val_loss: 1.0067 - val_acc: 0.5075\n",
      "Epoch 184/200\n",
      "6112/6216 [============================>.] - ETA: 0s - loss: 0.8832 - acc: 0.5767\n",
      "Epoch 00184: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8816 - acc: 0.5780 - val_loss: 1.0082 - val_acc: 0.5034\n",
      "Epoch 185/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8761 - acc: 0.5760\n",
      "Epoch 00185: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8763 - acc: 0.5767 - val_loss: 1.0085 - val_acc: 0.5075\n",
      "Epoch 186/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8818 - acc: 0.5694\n",
      "Epoch 00186: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8819 - acc: 0.5692 - val_loss: 1.0074 - val_acc: 0.5094\n",
      "Epoch 187/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 0.8723 - acc: 0.5806\n",
      "Epoch 00187: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 182us/step - loss: 0.8723 - acc: 0.5793 - val_loss: 1.0070 - val_acc: 0.5071\n",
      "Epoch 188/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8772 - acc: 0.5786\n",
      "Epoch 00188: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 181us/step - loss: 0.8775 - acc: 0.5783 - val_loss: 1.0087 - val_acc: 0.5034\n",
      "Epoch 189/200\n",
      "6128/6216 [============================>.] - ETA: 0s - loss: 0.8756 - acc: 0.5773\n",
      "Epoch 00189: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 207us/step - loss: 0.8761 - acc: 0.5775 - val_loss: 1.0091 - val_acc: 0.5045\n",
      "Epoch 190/200\n",
      "6032/6216 [============================>.] - ETA: 0s - loss: 0.8730 - acc: 0.5784\n",
      "Epoch 00190: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 207us/step - loss: 0.8718 - acc: 0.5796 - val_loss: 1.0100 - val_acc: 0.5041\n",
      "Epoch 191/200\n",
      "6144/6216 [============================>.] - ETA: 0s - loss: 0.8634 - acc: 0.5840\n",
      "Epoch 00191: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 190us/step - loss: 0.8625 - acc: 0.5849 - val_loss: 1.0111 - val_acc: 0.5049\n",
      "Epoch 192/200\n",
      "6064/6216 [============================>.] - ETA: 0s - loss: 0.8666 - acc: 0.5862\n",
      "Epoch 00192: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 193us/step - loss: 0.8669 - acc: 0.5859 - val_loss: 1.0118 - val_acc: 0.5068\n",
      "Epoch 193/200\n",
      "5984/6216 [===========================>..] - ETA: 0s - loss: 0.8776 - acc: 0.5780\n",
      "Epoch 00193: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 196us/step - loss: 0.8794 - acc: 0.5764 - val_loss: 1.0130 - val_acc: 0.5060\n",
      "Epoch 194/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 0.8681 - acc: 0.5797\n",
      "Epoch 00194: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 213us/step - loss: 0.8683 - acc: 0.5793 - val_loss: 1.0135 - val_acc: 0.5060\n",
      "Epoch 195/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8737 - acc: 0.5766\n",
      "Epoch 00195: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 209us/step - loss: 0.8743 - acc: 0.5758 - val_loss: 1.0148 - val_acc: 0.5060\n",
      "Epoch 196/200\n",
      "5920/6216 [===========================>..] - ETA: 0s - loss: 0.8721 - acc: 0.5792\n",
      "Epoch 00196: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 205us/step - loss: 0.8696 - acc: 0.5809 - val_loss: 1.0155 - val_acc: 0.5090\n",
      "Epoch 197/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8705 - acc: 0.5840\n",
      "Epoch 00197: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 206us/step - loss: 0.8704 - acc: 0.5832 - val_loss: 1.0162 - val_acc: 0.5045\n",
      "Epoch 198/200\n",
      "6096/6216 [============================>.] - ETA: 0s - loss: 0.8673 - acc: 0.5843\n",
      "Epoch 00198: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 232us/step - loss: 0.8681 - acc: 0.5845 - val_loss: 1.0173 - val_acc: 0.5060\n",
      "Epoch 199/200\n",
      "6160/6216 [============================>.] - ETA: 0s - loss: 0.8646 - acc: 0.5784\n",
      "Epoch 00199: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 215us/step - loss: 0.8649 - acc: 0.5780 - val_loss: 1.0192 - val_acc: 0.5049\n",
      "Epoch 200/200\n",
      "6080/6216 [============================>.] - ETA: 0s - loss: 0.8688 - acc: 0.5798\n",
      "Epoch 00200: val_loss did not improve\n",
      "6216/6216 [==============================] - 1s 227us/step - loss: 0.8694 - acc: 0.5795 - val_loss: 1.0177 - val_acc: 0.5049\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_acc', factor=0.9, patience=30, min_lr=0.000001, verbose=1)\n",
    "\n",
    "\n",
    "# this checkpointer lets save the weights\n",
    "# the option save_best_only is useful because it lets us save only the model with the best loss\n",
    "# so in case of overfitting, it lets us doing early-stopping\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=\"dl_emaus.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_k, y_train_k,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val_k, y_val_k),\n",
    "                    callbacks=[reduce_lr, checkpointer],\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:24:24.392814Z",
     "start_time": "2018-06-07T02:24:24.114192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a386ebdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a388be630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T02:33:16.226631Z",
     "start_time": "2018-06-06T02:33:16.220906Z"
    }
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:24:29.582323Z",
     "start_time": "2018-06-07T02:24:29.021951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.9886509097732223\n",
      "Validation accuracy: 0.5048798798798799\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"dl_emaus.hdf5\")\n",
    "\n",
    "# test dataset\n",
    "score_test = model.evaluate(x_val_k, y_val_k, verbose=0)\n",
    "print('Validation loss:', score_test[0])\n",
    "print('Validation accuracy:', score_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:24:50.783024Z",
     "start_time": "2018-06-07T02:24:50.246956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2664,)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob_pred = model.predict(x_val_k)\n",
    "y_pred = np.transpose(np.argmax(y_prob_pred, axis=1))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:24:54.874331Z",
     "start_time": "2018-06-07T02:24:54.866853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.49      0.51       986\n",
      "          1       0.25      0.56      0.35       394\n",
      "          2       0.75      0.50      0.60      1284\n",
      "\n",
      "avg / total       0.59      0.50      0.53      2664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:24:59.174370Z",
     "start_time": "2018-06-07T02:24:59.164957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[483, 312, 191],\n",
       "       [152, 221,  21],\n",
       "       [290, 353, 641]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the number of features is slightly different with the whole set, we need to train it once again but with time with the whole data (X_train = x_train + x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:29:37.770126Z",
     "start_time": "2018-06-07T02:27:01.776755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_89 (Dense)             (None, 128)               30464     \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 35,747\n",
      "Trainable params: 35,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/105\n",
      "8880/8880 [==============================] - 4s 403us/step - loss: 1.1364 - acc: 0.3310\n",
      "Epoch 2/105\n",
      " 880/8880 [=>............................] - ETA: 1s - loss: 1.1244 - acc: 0.3500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Selim/anaconda/lib/python3.6/site-packages/keras/callbacks.py:898: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/Users/Selim/anaconda/lib/python3.6/site-packages/keras/callbacks.py:406: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8880/8880 [==============================] - 2s 202us/step - loss: 1.1134 - acc: 0.3468\n",
      "Epoch 3/105\n",
      "8880/8880 [==============================] - 2s 192us/step - loss: 1.1040 - acc: 0.3551\n",
      "Epoch 4/105\n",
      "8880/8880 [==============================] - 2s 188us/step - loss: 1.1012 - acc: 0.3609\n",
      "Epoch 5/105\n",
      "8880/8880 [==============================] - 2s 188us/step - loss: 1.0980 - acc: 0.3584\n",
      "Epoch 6/105\n",
      "8880/8880 [==============================] - 2s 192us/step - loss: 1.0949 - acc: 0.3699 0s - loss: 1.0951 - acc\n",
      "Epoch 7/105\n",
      "8880/8880 [==============================] - 2s 193us/step - loss: 1.0937 - acc: 0.3745\n",
      "Epoch 8/105\n",
      "8880/8880 [==============================] - 2s 194us/step - loss: 1.0915 - acc: 0.3770\n",
      "Epoch 9/105\n",
      "8880/8880 [==============================] - 2s 194us/step - loss: 1.0871 - acc: 0.3744\n",
      "Epoch 10/105\n",
      "8880/8880 [==============================] - 2s 194us/step - loss: 1.0816 - acc: 0.3889\n",
      "Epoch 11/105\n",
      "8880/8880 [==============================] - 1s 167us/step - loss: 1.0812 - acc: 0.3909\n",
      "Epoch 12/105\n",
      "8880/8880 [==============================] - 1s 163us/step - loss: 1.0786 - acc: 0.4059\n",
      "Epoch 13/105\n",
      "8880/8880 [==============================] - 2s 174us/step - loss: 1.0768 - acc: 0.4028\n",
      "Epoch 14/105\n",
      "8880/8880 [==============================] - 1s 166us/step - loss: 1.0709 - acc: 0.4066\n",
      "Epoch 15/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0710 - acc: 0.4036\n",
      "Epoch 16/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0664 - acc: 0.4143\n",
      "Epoch 17/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0622 - acc: 0.4199\n",
      "Epoch 18/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 1.0611 - acc: 0.4227\n",
      "Epoch 19/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0585 - acc: 0.4204\n",
      "Epoch 20/105\n",
      "8880/8880 [==============================] - 1s 163us/step - loss: 1.0542 - acc: 0.4284\n",
      "Epoch 21/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 1.0500 - acc: 0.4334\n",
      "Epoch 22/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 1.0517 - acc: 0.4330\n",
      "Epoch 23/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0494 - acc: 0.4334\n",
      "Epoch 24/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0449 - acc: 0.4421\n",
      "Epoch 25/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 1.0408 - acc: 0.4411\n",
      "Epoch 26/105\n",
      "8880/8880 [==============================] - 1s 163us/step - loss: 1.0360 - acc: 0.4468\n",
      "Epoch 27/105\n",
      "8880/8880 [==============================] - 1s 164us/step - loss: 1.0387 - acc: 0.4438\n",
      "Epoch 28/105\n",
      "8880/8880 [==============================] - 1s 164us/step - loss: 1.0330 - acc: 0.4534\n",
      "Epoch 29/105\n",
      "8880/8880 [==============================] - 1s 163us/step - loss: 1.0331 - acc: 0.4497\n",
      "Epoch 30/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 1.0290 - acc: 0.4515\n",
      "Epoch 31/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0244 - acc: 0.4644\n",
      "Epoch 32/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0228 - acc: 0.4645\n",
      "Epoch 33/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0247 - acc: 0.4651\n",
      "Epoch 34/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0208 - acc: 0.4569\n",
      "Epoch 35/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0209 - acc: 0.4625\n",
      "Epoch 36/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0176 - acc: 0.4675\n",
      "Epoch 37/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 1.0152 - acc: 0.4716\n",
      "Epoch 38/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0103 - acc: 0.4706\n",
      "Epoch 39/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0084 - acc: 0.4735\n",
      "Epoch 40/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0071 - acc: 0.4729\n",
      "Epoch 41/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 1.0072 - acc: 0.4734\n",
      "Epoch 42/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0108 - acc: 0.4715\n",
      "Epoch 43/105\n",
      "8880/8880 [==============================] - 1s 160us/step - loss: 1.0060 - acc: 0.4777\n",
      "Epoch 44/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 1.0019 - acc: 0.4698\n",
      "Epoch 45/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 1.0047 - acc: 0.4812\n",
      "Epoch 46/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9980 - acc: 0.4837\n",
      "Epoch 47/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9975 - acc: 0.4834\n",
      "Epoch 48/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9983 - acc: 0.4836\n",
      "Epoch 49/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 0.9962 - acc: 0.4873\n",
      "Epoch 50/105\n",
      "8880/8880 [==============================] - 1s 157us/step - loss: 0.9938 - acc: 0.4849\n",
      "Epoch 51/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9949 - acc: 0.4851\n",
      "Epoch 52/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9894 - acc: 0.4890\n",
      "Epoch 53/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9909 - acc: 0.4929\n",
      "Epoch 54/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9894 - acc: 0.4876\n",
      "Epoch 55/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9820 - acc: 0.5015\n",
      "Epoch 56/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 0.9860 - acc: 0.4911\n",
      "Epoch 57/105\n",
      "8880/8880 [==============================] - 1s 163us/step - loss: 0.9843 - acc: 0.4973\n",
      "Epoch 58/105\n",
      "8880/8880 [==============================] - 1s 163us/step - loss: 0.9829 - acc: 0.4958\n",
      "Epoch 59/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9841 - acc: 0.5007\n",
      "Epoch 60/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9774 - acc: 0.4979\n",
      "Epoch 61/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9795 - acc: 0.4962\n",
      "Epoch 62/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9756 - acc: 0.4992\n",
      "Epoch 63/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9766 - acc: 0.5014\n",
      "Epoch 64/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9774 - acc: 0.5038\n",
      "Epoch 65/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9773 - acc: 0.5026\n",
      "Epoch 66/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9734 - acc: 0.5009\n",
      "Epoch 67/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9772 - acc: 0.5000\n",
      "Epoch 68/105\n",
      "8880/8880 [==============================] - 2s 173us/step - loss: 0.9747 - acc: 0.4972\n",
      "Epoch 69/105\n",
      "8880/8880 [==============================] - 1s 162us/step - loss: 0.9727 - acc: 0.5050\n",
      "Epoch 70/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9665 - acc: 0.5124\n",
      "Epoch 71/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9709 - acc: 0.5068\n",
      "Epoch 72/105\n",
      "8880/8880 [==============================] - 1s 160us/step - loss: 0.9669 - acc: 0.5048\n",
      "Epoch 73/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9689 - acc: 0.5051\n",
      "Epoch 74/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9647 - acc: 0.5092\n",
      "Epoch 75/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9664 - acc: 0.5115\n",
      "Epoch 76/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9654 - acc: 0.5069\n",
      "Epoch 77/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9617 - acc: 0.5137\n",
      "Epoch 78/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9610 - acc: 0.5108\n",
      "Epoch 79/105\n",
      "8880/8880 [==============================] - 1s 163us/step - loss: 0.9706 - acc: 0.5059\n",
      "Epoch 80/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9577 - acc: 0.5173\n",
      "Epoch 81/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9596 - acc: 0.5114\n",
      "Epoch 82/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9561 - acc: 0.5136\n",
      "Epoch 83/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9611 - acc: 0.5101\n",
      "Epoch 84/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9542 - acc: 0.5144\n",
      "Epoch 85/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9568 - acc: 0.5158\n",
      "Epoch 86/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9477 - acc: 0.5218\n",
      "Epoch 87/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9503 - acc: 0.5193\n",
      "Epoch 88/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9543 - acc: 0.5196\n",
      "Epoch 89/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9537 - acc: 0.5179\n",
      "Epoch 90/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9522 - acc: 0.5199\n",
      "Epoch 91/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9506 - acc: 0.5170\n",
      "Epoch 92/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9462 - acc: 0.5221\n",
      "Epoch 93/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9457 - acc: 0.5229\n",
      "Epoch 94/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9434 - acc: 0.5280\n",
      "Epoch 95/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9431 - acc: 0.5287\n",
      "Epoch 96/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9437 - acc: 0.5214\n",
      "Epoch 97/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9460 - acc: 0.5200\n",
      "Epoch 98/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9420 - acc: 0.5242\n",
      "Epoch 99/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9463 - acc: 0.5222\n",
      "Epoch 100/105\n",
      "8880/8880 [==============================] - 1s 160us/step - loss: 0.9411 - acc: 0.5221\n",
      "Epoch 101/105\n",
      "8880/8880 [==============================] - 1s 160us/step - loss: 0.9357 - acc: 0.5244\n",
      "Epoch 102/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9441 - acc: 0.5261\n",
      "Epoch 103/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9385 - acc: 0.5305\n",
      "Epoch 104/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9377 - acc: 0.5328\n",
      "Epoch 105/105\n",
      "8880/8880 [==============================] - 1s 161us/step - loss: 0.9353 - acc: 0.5312\n"
     ]
    }
   ],
   "source": [
    "# we select 105 epochs which is the inflection point during the model training/testing\n",
    "# this is early-stopping, a way to reduce over-fitting\n",
    "epochs = 105\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# fully connected layers\n",
    "# layer1\n",
    "model.add(Dense(layer1, activation='relu', input_dim=input_layer))\n",
    "# input_dim is the number of inputs\n",
    "\n",
    "# dropout\n",
    "model.add(Dropout(drop_prob))\n",
    "\n",
    "# layer2\n",
    "model.add(Dense(layer2, activation='relu'))\n",
    "\n",
    "# dropout\n",
    "model.add(Dropout(drop_prob))\n",
    "\n",
    "# layer3\n",
    "model.add(Dense(layer3, activation='relu'))\n",
    "\n",
    "# dropout\n",
    "model.add(Dropout(drop_prob))\n",
    "\n",
    "# layer4\n",
    "#model.add(Dense(layer4, activation='relu'))\n",
    "\n",
    "# dropout\n",
    "# model.add(Dropout(drop_prob))\n",
    "\n",
    "# layer5\n",
    "#model.add(Dense(layer5, activation='relu'))\n",
    "# dropout\n",
    "# model.add(Dropout(drop_prob))\n",
    "\n",
    "# softmax layer\n",
    "# the softmax layer produces probability\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# Visualizing the model\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_acc', factor=0.9, patience=30, min_lr=0.000001, verbose=1)\n",
    "\n",
    "\n",
    "# this checkpointer lets save the weights\n",
    "# the option save_best_only is useful because it lets us save only the model with the best loss\n",
    "# so in case of overfitting, it lets us doing early-stopping\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=\"dl_emaus.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_k, Y_train_k,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=1,\n",
    "                    callbacks=[reduce_lr, checkpointer],\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:29:42.800992Z",
     "start_time": "2018-06-07T02:29:42.089944Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_prob_pred = model.predict(X_test_k)\n",
    "df_submission = pd.DataFrame(Y_prob_pred, index=X_test.index)\n",
    "df_submission.to_csv(\"my_prediction_nn2.csv\",\n",
    "                     index_label=\"id\", header=['0', '1', '2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I scored <b>0.99662</b> on the platform with this model.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
